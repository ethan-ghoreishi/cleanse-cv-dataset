{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "import types\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.tokenize as nt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from textblob import blob, Blobber, TextBlob, Sentence, Word, WordList, tokenizers, sentiments, taggers, parsers, classifiers\n",
    "#from textblob_aptagger import PerceptronTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = psycopg2.connect(dbname=\"skillsdb\",host=\"dw-instance.cbrlhmbtfrqg.eu-west-2.redshift.amazonaws.com\"\n",
    "                ,port=\"5439\",user=\"masteruser\", password=\"Ehgh1363\")\n",
    "curs = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0   5049"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('''select count(distinct user_id) from cv''',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_sql_query('''select distinct cv.user_id, cv_section_attribute.name,\n",
    "cv.value_char, cv.value_timestamp from cv_section_attribute \n",
    "left join cv on cv_section_attribute.id=cv.cv_section_attribute_id''',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data['value_char'] = data['value_char'].map(lambda x: x.strip() if pd.notnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>value_char</th>\n",
       "      <th>value_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.257237e+11</td>\n",
       "      <td>name</td>\n",
       "      <td>Freelance Copy Editor of 100</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.987262e+11</td>\n",
       "      <td>admit_year</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.987262e+11</td>\n",
       "      <td>grad_year</td>\n",
       "      <td>present</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.987262e+11</td>\n",
       "      <td>admit_year</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.987262e+11</td>\n",
       "      <td>admit_year</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        name                    value_char value_timestamp\n",
       "0  3.257237e+11        name  Freelance Copy Editor of 100             NaT\n",
       "1  1.987262e+11  admit_year                          None      2016-01-01\n",
       "2  1.987262e+11   grad_year                       present             NaT\n",
       "3  1.987262e+11  admit_year                          None      2015-01-01\n",
       "4  1.987262e+11  admit_year                          None      2012-01-01"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>value_char</th>\n",
       "      <th>value_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.257237e+11</td>\n",
       "      <td>name</td>\n",
       "      <td>Freelance Copy Editor of 100</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.987262e+11</td>\n",
       "      <td>admit_year</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.987262e+11</td>\n",
       "      <td>grad_year</td>\n",
       "      <td>present</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.987262e+11</td>\n",
       "      <td>admit_year</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.987262e+11</td>\n",
       "      <td>admit_year</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        name                    value_char value_timestamp\n",
       "0  3.257237e+11        name  Freelance Copy Editor of 100             NaT\n",
       "1  1.987262e+11  admit_year                          None      2016-01-01\n",
       "2  1.987262e+11   grad_year                       present             NaT\n",
       "3  1.987262e+11  admit_year                          None      2015-01-01\n",
       "4  1.987262e+11  admit_year                          None      2012-01-01"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid = data[data['name'].isin(['locale','name','summary','headline',\n",
    "                                     'degree','school','admit_year','grad_year',\n",
    "                                     'company',  'title',  'work_location',  \n",
    "                                     'start_date','end_date', 'description',\n",
    "                                     'award',\n",
    "                                     'publication', \n",
    "                                     'additional_info', \n",
    "                                     'skill'])]\n",
    "data_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(prefix=None):\n",
    "    '''\n",
    "    Cleans text data by:\n",
    "    1.  force lowercase\n",
    "    2.  remove non-ascii chars\n",
    "    3.  standardize whitespace\n",
    "    4.  remove digits\n",
    "    5.  remove control characters\n",
    "    6.  remove URL patterns\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        df = data_valid[prefix].dropna().map(lambda x: \"\".join(i for i in x.strip().lower() if ord(i)<128))\n",
    "    except UnicodeDecodeError:\n",
    "        print(UnicodeDecodeError)\n",
    "        df = data_valid[prefix].dropna().map(lambda x: x.strip().lower())\n",
    "\n",
    "        #     except Exception:\n",
    "#         print(Exception)\n",
    "#     finally:\n",
    "#         data[prefix]= data[prefix].map(lambda x: x.lower())\n",
    "\n",
    "    url_pattern = \"((http|ftp|https):\\/\\/)?[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;/~\\+#])?\"\n",
    "\n",
    "    re_URL = re.compile(url_pattern)\n",
    "#     re_TAG = re.compile(\"(<[phl]>)\", re.IGNORECASE)\n",
    "    re_WS = re.compile(\"/[^\\S\\n]/\")\n",
    "#     re_DIGIT = re.compile(\"\\d\")\n",
    "    re_CTRL = re.compile(\"[\\x00-\\x11\\x03-\\x1F]+\")\n",
    "    re_HI = re.compile(\"[\\x80-\\xFF]+\")\n",
    "    re_NWC = re.compile(\"[!;<>?{}\\/~`#=@#$%^&*()_+]\")\n",
    "    \n",
    "    df = df.map(lambda x: re_HI.sub(' ', x))\n",
    "    df = df.map(lambda x: re_CTRL.sub(' ', x))\n",
    "    df = df.map(lambda x: re_URL.sub(' ', x))\n",
    "#     data[prefix] = data[prefix].map(lambda x: re_DIGIT.sub(' ', x))\n",
    "    df = df.map(lambda x: re_WS.sub(' ', x))        \n",
    "    df = df.map(lambda x: re_NWC.sub(' ', x))\n",
    "    df = df.map(lambda x: x.strip())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             freelance copy editor of 100\n",
       "2                                  present\n",
       "5    research and commercialisation intern\n",
       "6             hold full uk driving license\n",
       "8            volunteer  campsite attendant\n",
       "Name: value_char, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('value_char').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freelance copy editor of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>research and commercialisation intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hold full uk driving license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>volunteer  campsite attendant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              value_char\n",
       "0           freelance copy editor of 100\n",
       "2                                present\n",
       "5  research and commercialisation intern\n",
       "6           hold full uk driving license\n",
       "8          volunteer  campsite attendant"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.DataFrame()\n",
    "data_clean['value_char'] = clean_text('value_char')\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_valid = data_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Tokenization\n",
    "\n",
    "# # initialize the tokenizer\n",
    "\n",
    "# tokenizer = nltk.tokenize.PunktSentenceTokenizer()\n",
    "\n",
    "# # tokenize data\n",
    "\n",
    "# data_clean['value_char'] = data_clean['value_char'].map(lambda x: tokenizer.tokenize(x.strip()))\n",
    "# data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word_tokenizer = nltk.tokenize.word_tokenize()\n",
    "# data_clean['value_char'] = data_clean['value_char'].map(lambda x: nltk.tokenize.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Stemming\n",
    "\n",
    "# # initialize the stemmer\n",
    "\n",
    "# stemmer = nltk.stem.PorterStemmer()\n",
    "# # data_clean['value_char'].map(lambda x: (i for i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lemmatize = nltk.WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cv_headlines = data[data['name'] == 'headline'].reset_index()[['user_id','value_char']]\n",
    "# cv_degrees = data[data['name'] == 'degree'].reset_index()[['user_id','value_char']]\n",
    "# cv_schools = data[data['name'] == 'school'].reset_index()[['user_id','value_char']]\n",
    "# cv_locales = data[data['name'] == 'locale'].reset_index()[['user_id','value_char']]\n",
    "# cv_summaries = data[data['name'] == 'summary'].reset_index()[['user_id','value_char']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "tokenizer_prefs = {\n",
    "    'tokenizer' : nltk.tokenize.PunktSentenceTokenizer(),\n",
    "#     'token_format' : 'stem',\n",
    "    'spell_correct' : False,\n",
    "    'np_extract': None,\n",
    "    'pos_tagger': None,\n",
    "    'analyzer': None,\n",
    "    'classifier': None, \n",
    "    'clean_html': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_blob(prefix, **kwargs):\n",
    "    \n",
    "    tokenizer = kwargs['tokenizer']\n",
    "    pos_tagger = kwargs['pos_tagger']\n",
    "    analyzer = kwargs['analyzer']\n",
    "    classifier = kwargs['classifier']\n",
    "    np_extract = kwargs['np_extract']\n",
    "    \n",
    "    blob = data_clean[prefix].map(lambda l: TextBlob(l,\n",
    "                                          tokenizer=tokenizer,\n",
    "                                           np_extractor=np_extract,\n",
    "                                           pos_tagger=pos_tagger,\n",
    "                                           analyzer=analyzer,\n",
    "                                           classifier=classifier))\n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (f, r, e, e, l, a, n, c, e,  , c, o, p, y,  , ...\n",
       "2                                 (p, r, e, s, e, n, t)\n",
       "5     (r, e, s, e, a, r, c, h,  , a, n, d,  , c, o, ...\n",
       "6     (h, o, l, d,  , f, u, l, l,  , u, k,  , d, r, ...\n",
       "8     (v, o, l, u, n, t, e, e, r,  ,  , c, a, m, p, ...\n",
       "9                                    (s, k, i, l, l, s)\n",
       "10    (l, i, g, h, t, -, s, c, a, t, t, e, r, i, n, ...\n",
       "13    (p, o, s, t, -, d, o, c, t, o, r, a, l,  , r, ...\n",
       "14    (t, e, a, m,  , l, e, a, d, e, r,  ,  ,  , n, ...\n",
       "15           (r, e, l, i, e, f,  , m, a, n, a, g, e, r)\n",
       "Name: value_char, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_blobs = pd.DataFrame()\n",
    "data_blobs['value_char'] = create_blob('value_char', **tokenizer_prefs)\n",
    "data_blobs.value_char[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_sentences(prefix):\n",
    "#     tokenizer = kwargs['tokenizer']\n",
    "#     normalizer = kwargs['token_format']\n",
    "\n",
    "    # tokenize the document into sentences from blob object\n",
    "    sentences = data_blobs[prefix].map(lambda s: s.sentences)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [(f, r, e, e, l, a, n, c, e,  , c, o, p, y,  ,...\n",
       "2                               [(p, r, e, s, e, n, t)]\n",
       "5     [(r, e, s, e, a, r, c, h,  , a, n, d,  , c, o,...\n",
       "6     [(h, o, l, d,  , f, u, l, l,  , u, k,  , d, r,...\n",
       "8     [(v, o, l, u, n, t, e, e, r,  ,  , c, a, m, p,...\n",
       "9                                  [(s, k, i, l, l, s)]\n",
       "10    [(l, i, g, h, t, -, s, c, a, t, t, e, r, i, n,...\n",
       "13    [(p, o, s, t, -, d, o, c, t, o, r, a, l,  , r,...\n",
       "14    [(t, e, a, m,  , l, e, a, d, e, r,  ,  ,  , n,...\n",
       "15         [(r, e, l, i, e, f,  , m, a, n, a, g, e, r)]\n",
       "Name: value_char, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sentence_tokenized = pd.DataFrame()\n",
    "data_sentence_tokenized['value_char'] = tokenize_sentences('value_char')\n",
    "data_sentence_tokenized.value_char[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_words(prefix):\n",
    "#     tokenizer = kwargs['tokenizer']\n",
    "#     normalizer = kwargs['token_format']\n",
    "\n",
    "    # tokenize each sentence into words\n",
    "    # trim token whitespaces\n",
    "    # eliminate tokens of character length 1\n",
    "    #words = self.data[prefix].map(lambda w: w.strip().tokens if len(w)>1 else None)\n",
    "\n",
    "    words = data_sentence_tokenized[prefix].map(lambda l: map(lambda w: w.strip().words if len(w)>1 else None, l))\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_word_tokenized = pd.DataFrame()\n",
    "data_word_tokenized = tokenize_words('value_char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_data(data_word_tokenized):\n",
    "#     tokenizer = kwargs['tokenizer']\n",
    "#     normalizer = kwargs['token_format']\n",
    "#     spelling = kwargs['spell_correct']\n",
    "    \n",
    "    data_normalized = data_word_tokenized.map(lambda l: map(lambda w: w.singularize() if not isinstance(w, type(None)) and len(w)>1 else None, l))\n",
    "#     data_normalized = data_normalized.dropna()\n",
    "    \n",
    "    # filter out 'bad' words, normalize good ones\n",
    "    # w if w not in self.stopWords else wl.remove(w)\n",
    "#     data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w in stopWords and not isinstance(w, type(None)) else w, wl), l))\n",
    "#     data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'s' and not isinstance(w, type(None) else w, wl), l))\n",
    "#     data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'d' and not isinstance(w, type(None) else w, wl), l))\n",
    "#     data_normalized = data_normalized.dropna()\n",
    "\n",
    "     # remove tokens with length 1\n",
    "#     ree = re.compile(r'(\\'\\w)')\n",
    "#     rlen = len(data_normalized)\n",
    "#     tmp = data_normalized.copy()\n",
    "# #     tmp.reset_index(drop=True)\n",
    "#     for indx in tmp.index:\n",
    "#          wl_coll = list()\n",
    "#          for i in normalize(data_word_tokenized,**tokenizer_prefs):\n",
    "#             for j in i:\n",
    "#                 if not isinstance(j, type(None)):\n",
    "#                     for k in j:\n",
    "#                         if not isinstance(k, type(None)):\n",
    "#                             if re.match(ree, i):\n",
    "#                                 ree.sub('', i)\n",
    "#                             if len(i.strip().strip('.').strip(',')) > 1:\n",
    "#                                 wl.append((i))\n",
    "#                     wl_coll.append(WordList(wl))\n",
    "#             data_normalized[indx] = wl_col\n",
    "#             del tmp\n",
    "\n",
    "    # stemming\n",
    "#     data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: nltk.stemmer.stem(w) if w in wl and not isinstance(w, types.NoneType) else wl.remove(w), wl), l))\n",
    "\n",
    "#     data_word_tokenized= tokenize_words('value_char', **tokenizer_prefs)\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_normalized = normalize_data(data_word_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if not isinstance(data_normalized, type(None)):\n",
    "#     for i in data_normalized:\n",
    "#         if not isinstance(i, type(None)):\n",
    "#             for j in i:\n",
    "#                 if not isinstance(j, type(None)):\n",
    "#                     for k in j:\n",
    "#                         if not isinstance(k, type(None)) and k not in stopWords and k != '\\'s' and k != '\\'d':\n",
    "#                             print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_vocab(data_normalized, target):\n",
    "    vocab = set()\n",
    "    if not isinstance(data_normalized, type(None)):\n",
    "        for token in data_normalized:\n",
    "            if not isinstance(token, type(None)):\n",
    "                for sentence in token:\n",
    "                    if not isinstance(sentence, type(None)):\n",
    "                        for word in sentence:\n",
    "                            if not isinstance(word, type(None)) and word not in stopWords and word != '\\'s' and word != '\\'d':\n",
    "                                vocab.add(word)\n",
    "            \n",
    "    if target:\n",
    "        w2i = {w: np.int32(i+2) for i, w in enumerate(vocab)}\n",
    "        w2i['<s>'], w2i['</s>'] = np.int32(0), np.int32(1)\n",
    "    else:\n",
    "        w2i = {w: np.int32(i) for i, w in enumerate(vocab)}\n",
    "\n",
    "    return w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2i = build_vocab(data_normalized, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hypothesi': 2,\n",
       " 'etching': 3,\n",
       " 'orthopedist': 4,\n",
       " 'premiere-based': 5,\n",
       " 'perday': 6,\n",
       " 'andposition': 7,\n",
       " 'outlay': 8,\n",
       " 'lorry': 10,\n",
       " 'gallup': 36256,\n",
       " 'semisolid': 11,\n",
       " '2013tinatus': 12,\n",
       " 'sister': 13,\n",
       " 'became': 14,\n",
       " 'geometryal-qud': 15,\n",
       " 'vmsimplementing': 16,\n",
       " 'sh': 17,\n",
       " 'rutgers-the': 18,\n",
       " 'dorotocephala': 19,\n",
       " 'windowsapplication': 20,\n",
       " '2015led': 21,\n",
       " '850,856': 27051,\n",
       " 'othersfocused': 22,\n",
       " 'sasproject': 8931,\n",
       " '429': 23,\n",
       " 'benefitsresource': 24,\n",
       " 'data-cabling': 25,\n",
       " 'developmentfinancial': 26,\n",
       " 'thesis-analyzed': 27053,\n",
       " 'reportsquality': 28,\n",
       " 'steward': 30,\n",
       " 'aif': 33,\n",
       " 'pyrolysi': 44143,\n",
       " 'analysisconsultantsagile': 34,\n",
       " 'r2application': 36,\n",
       " 'syspro': 42,\n",
       " 'deliving': 38,\n",
       " 't2': 39,\n",
       " 'compounddissolution': 41,\n",
       " 'whilstbeing': 9407,\n",
       " 'dorado': 9,\n",
       " '2764': 46675,\n",
       " 'emphasize': 43,\n",
       " \"'student\": 44,\n",
       " 'arts-political': 45,\n",
       " 'stagecommunicating': 49,\n",
       " 'severely': 48,\n",
       " 'catalua': 8937,\n",
       " 'best-of': 50,\n",
       " 'instance': 51,\n",
       " 'financeuniversity': 8938,\n",
       " 'servicesprofessional': 52,\n",
       " 'accountingdocument': 53,\n",
       " 'lif': 48454,\n",
       " 'hello': 54,\n",
       " '250inmate': 55,\n",
       " 'continue': 56,\n",
       " 'brewery': 26082,\n",
       " 'clr': 57,\n",
       " 'transferrable': 59,\n",
       " 'bike': 60,\n",
       " '2011financial': 61,\n",
       " 'wright': 36020,\n",
       " 'neurologic': 62,\n",
       " 'customizing': 63,\n",
       " 's26responsibility': 64,\n",
       " 'galloway': 36024,\n",
       " 'analysisof': 65,\n",
       " 'submitted': 66,\n",
       " 'microfluidic': 48016,\n",
       " 'availability': 8943,\n",
       " 'rfu': 67,\n",
       " 'kadry': 68,\n",
       " 'qtpsoftware': 69,\n",
       " 'caused': 70,\n",
       " 'freelancetrainer': 71,\n",
       " 'aktum': 72,\n",
       " 'statewide': 73,\n",
       " 'colorectal': 75,\n",
       " 'accounting-tbc': 45043,\n",
       " 'pro-on': 77,\n",
       " 'lomonosov': 8947,\n",
       " 'london-based': 78,\n",
       " 'conductedclient': 27063,\n",
       " 'mastcraft': 79,\n",
       " 'undermanned': 80,\n",
       " 'wing': 81,\n",
       " 'git': 82,\n",
       " 'stroke': 85,\n",
       " 'steel': 23910,\n",
       " 'crossvalidation': 48503,\n",
       " 'bramall': 86,\n",
       " 'bi-direction': 87,\n",
       " 'sputum': 88,\n",
       " 'meetcorporate': 4114,\n",
       " 'hauler': 89,\n",
       " 'strict': 90,\n",
       " '2014undergraduate': 91,\n",
       " 'microreactor': 92,\n",
       " 'elaborating': 93,\n",
       " 'e-signal': 94,\n",
       " 'storming': 8800,\n",
       " 'international': 95,\n",
       " 'achievablestandard': 96,\n",
       " 'richfield': 98,\n",
       " 'minuscule': 18020,\n",
       " '627': 101,\n",
       " 'ms-accesstesting': 100,\n",
       " '89-94': 102,\n",
       " 'oc4j': 103,\n",
       " 'mccarthy': 104,\n",
       " 'mcandrew': 105,\n",
       " 'geoved': 27066,\n",
       " 'bailey': 106,\n",
       " 'plug-in': 108,\n",
       " 'notable': 109,\n",
       " '15614': 111,\n",
       " 'shut': 27068,\n",
       " 'bluejuly': 112,\n",
       " 'multi-warehouseenvironment': 117,\n",
       " 'labconnect': 114,\n",
       " 'astute': 115,\n",
       " 'shipsformalized': 116,\n",
       " 'midatech': 45052,\n",
       " 'vision': 118,\n",
       " 'protocol': 49876,\n",
       " 'il-34': 8952,\n",
       " 'jnt': 121,\n",
       " 'nexusand': 120,\n",
       " 'yellowdot': 122,\n",
       " 'maximizer': 37061,\n",
       " 'flushed': 124,\n",
       " 'pressured': 125,\n",
       " 'disassembler': 126,\n",
       " 'defending': 127,\n",
       " 'agarwal': 128,\n",
       " 'superficial': 129,\n",
       " 'straus': 130,\n",
       " 'blocker': 131,\n",
       " 'consultantworked': 8958,\n",
       " 'hong': 132,\n",
       " 'accountscommunicated': 134,\n",
       " 'wicker': 135,\n",
       " 'sanef': 136,\n",
       " 'mef': 137,\n",
       " 'plc5': 15796,\n",
       " 'nut': 138,\n",
       " 'jit': 36037,\n",
       " 'shukla': 139,\n",
       " 'akademie': 144,\n",
       " 'seal': 141,\n",
       " 'mcpconfiguring': 142,\n",
       " 'kmhisi': 145,\n",
       " 'dataand': 146,\n",
       " 'benefitmanagement': 147,\n",
       " 'lumension': 148,\n",
       " 'mention': 150,\n",
       " 'science-chemical': 151,\n",
       " 'backup-exec': 27071,\n",
       " '10-cm': 152,\n",
       " 'inflicted': 153,\n",
       " 'toilet': 154,\n",
       " 'hawkin': 155,\n",
       " 'a3500austin': 156,\n",
       " 'r2r': 161,\n",
       " 'learnerhighly': 159,\n",
       " 'babitum': 27075,\n",
       " 'townhouse': 164,\n",
       " 'booking': 165,\n",
       " 'antineoplastic': 166,\n",
       " 'monetory': 168,\n",
       " 'itn': 169,\n",
       " 'tesco': 36041,\n",
       " 'silva': 170,\n",
       " 'lambert': 171,\n",
       " 'offlorida': 172,\n",
       " 'dated': 173,\n",
       " 'non-u': 44789,\n",
       " 'impedance': 174,\n",
       " 'mclaren': 176,\n",
       " 'engl': 177,\n",
       " 'learn': 178,\n",
       " 'reductase': 180,\n",
       " 'bugzillaa': 18033,\n",
       " 'investing': 181,\n",
       " 'philadelphium': 182,\n",
       " 'innotec': 20293,\n",
       " 'max': 45062,\n",
       " 'telcordium': 183,\n",
       " 'divinitati': 184,\n",
       " 'viewing': 185,\n",
       " '64th': 186,\n",
       " 'overspent': 18044,\n",
       " 'short-term': 187,\n",
       " 'cadd': 188,\n",
       " 'redirecting': 189,\n",
       " 'seite': 36047,\n",
       " 'tsafleb': 192,\n",
       " 'skillsexpert': 193,\n",
       " 'eagerly': 194,\n",
       " 'invocation': 27079,\n",
       " '23m': 195,\n",
       " 'bishop': 196,\n",
       " 'h2o': 197,\n",
       " 'externalongoing': 198,\n",
       " 'clean-desk': 199,\n",
       " 'average': 200,\n",
       " '55th': 201,\n",
       " 'advisingcustomer': 18227,\n",
       " 'welding': 202,\n",
       " 'strove': 203,\n",
       " '7798731067': 205,\n",
       " 'pentagon': 207,\n",
       " 'diverting': 209,\n",
       " 'kingdomnovember': 208,\n",
       " 'uphold': 210,\n",
       " 'wal-mart': 211,\n",
       " 'worker-therapist': 27,\n",
       " 'harrisburg': 213,\n",
       " 'vliegende': 214,\n",
       " 'experienceunix': 216,\n",
       " 'phosphospermine': 219,\n",
       " 'solutionsdesigned': 29,\n",
       " 'trud': 220,\n",
       " 'for50': 221,\n",
       " 'reagent': 222,\n",
       " 'officedelivering': 225,\n",
       " 'cognate': 224,\n",
       " 'iiipace': 229,\n",
       " 'ministerial': 227,\n",
       " 'teachingdecember': 31,\n",
       " 'remington': 230,\n",
       " 'time-by': 232,\n",
       " 'fbusines': 233,\n",
       " 'multilingual': 234,\n",
       " 'ending': 235,\n",
       " 'makongorosi': 236,\n",
       " 'phonetically': 237,\n",
       " '2016hillingdon': 35,\n",
       " 'exhibit': 29886,\n",
       " 'ln7075': 45074,\n",
       " 're-pricing': 239,\n",
       " 'alstom': 27088,\n",
       " 'eventreporting': 240,\n",
       " 'eproject': 241,\n",
       " 'siebe': 242,\n",
       " 'clearing': 243,\n",
       " 'gida': 244,\n",
       " 'freelancer': 245,\n",
       " 'rmysql': 246,\n",
       " 'ensheathing': 247,\n",
       " 'lf': 8970,\n",
       " 'judging': 248,\n",
       " 'university-metropolitan': 249,\n",
       " 'newbusines': 250,\n",
       " 'kuznetsov': 251,\n",
       " 'centeravaloq': 252,\n",
       " 'accountantconvenience': 253,\n",
       " 'sur': 255,\n",
       " 'kitnlp': 256,\n",
       " 'exceeded': 257,\n",
       " 'sessional': 258,\n",
       " 'rupee': 8974,\n",
       " 'mid1': 259,\n",
       " 'oncology': 260,\n",
       " 'rawalpindi': 45080,\n",
       " 'captioning': 37,\n",
       " 'analysislanguage': 261,\n",
       " 'gdansk': 262,\n",
       " 'gem': 263,\n",
       " '95willing': 27096,\n",
       " 'cpuc': 264,\n",
       " 'englishadditional': 265,\n",
       " 'looming': 266,\n",
       " 'abi': 40,\n",
       " 'grigg': 267,\n",
       " 'strumica': 268,\n",
       " 'forecastedcashflow': 269,\n",
       " 'bcg': 270,\n",
       " 'kalamazoo': 271,\n",
       " 'interning': 44523,\n",
       " 're-negotiated': 272,\n",
       " 'equallogic': 273,\n",
       " 'memcache': 8976,\n",
       " 'gyro': 274,\n",
       " 'patio': 275,\n",
       " 'nue': 276,\n",
       " 'classifiero': 277,\n",
       " 'v1612': 278,\n",
       " 'either': 281,\n",
       " 'autoglas': 284,\n",
       " 'recrystallization': 283,\n",
       " 'maropost': 6914,\n",
       " 'cross-database': 288,\n",
       " 'grc': 286,\n",
       " 'mfr': 287,\n",
       " 'early-warning': 290,\n",
       " 'claims-c1-efs-sfdc': 51102,\n",
       " 'jrd': 51673,\n",
       " 'three-person': 291,\n",
       " 'manufacturejba': 43658,\n",
       " 'assembly': 292,\n",
       " 'endodonthic': 294,\n",
       " 'testopium': 295,\n",
       " 'pander': 296,\n",
       " '2006-august': 297,\n",
       " 'igrafix': 298,\n",
       " 'illionoi': 27101,\n",
       " 'thinkingjennifer': 299,\n",
       " 'policlinico': 300,\n",
       " 'usingvba': 301,\n",
       " 'testedcompound': 302,\n",
       " 'universally': 303,\n",
       " 're-education': 48407,\n",
       " 'luggage': 304,\n",
       " 'educationgrade': 46,\n",
       " 'compounds2004detection': 305,\n",
       " 'quality-assurance': 50191,\n",
       " 'sapperson': 47,\n",
       " 'servermobile': 306,\n",
       " 'bioinformatician': 307,\n",
       " 'bdiploma': 308,\n",
       " 'branchburg': 36065,\n",
       " 'education-professional': 309,\n",
       " 'humoured': 12997,\n",
       " 'eev': 314,\n",
       " '120mmscf': 311,\n",
       " 'user-friend': 313,\n",
       " 'resolving': 29506,\n",
       " 'eye': 315,\n",
       " 'harmony': 316,\n",
       " 'alloy': 317,\n",
       " 'kingshurt': 27089,\n",
       " 'zro2': 318,\n",
       " 'forging': 320,\n",
       " 'topotential': 321,\n",
       " 'lm': 322,\n",
       " 'polymeric': 323,\n",
       " 'brca1pedigree': 324,\n",
       " 'riccarton': 327,\n",
       " 'analystdowner': 328,\n",
       " 'elicited': 329,\n",
       " 'spanish-speaking': 330,\n",
       " 'christleton': 331,\n",
       " 'suggestedthe': 8988,\n",
       " 'parenting': 18060,\n",
       " 'webproduct': 332,\n",
       " 'spectral': 333,\n",
       " 'viscoelastic': 334,\n",
       " 'factoranalysi': 18061,\n",
       " 'ubo': 8990,\n",
       " 'scrivner': 29669,\n",
       " 'changeover': 27111,\n",
       " '27th': 335,\n",
       " '06': 337,\n",
       " 'repression': 338,\n",
       " 'councilconducted': 339,\n",
       " 'helico': 340,\n",
       " 'medimmune': 18067,\n",
       " 'phenomenon': 341,\n",
       " 'telepresence': 342,\n",
       " 'norlington': 18071,\n",
       " 'disapprove': 344,\n",
       " 'mnm': 345,\n",
       " 'nco': 8994,\n",
       " 'kick': 346,\n",
       " 'pharmacotherapy': 347,\n",
       " 'publicized': 348,\n",
       " 'techniqueso': 45101,\n",
       " 'rcf': 349,\n",
       " '5-10': 350,\n",
       " 'vbdatabasis': 351,\n",
       " 'lifepoint': 24224,\n",
       " 'ideal': 352,\n",
       " 'peritz': 51677,\n",
       " 'combing': 353,\n",
       " 'carrot-top': 354,\n",
       " 'insightmarvin-fresh': 356,\n",
       " 'sortino': 357,\n",
       " \"'test\": 358,\n",
       " 'un-necessary': 359,\n",
       " 'electricand': 360,\n",
       " 'uniliver': 361,\n",
       " 'db2environmentetl': 362,\n",
       " 'cif': 49598,\n",
       " 'designnational': 363,\n",
       " 'girl': 364,\n",
       " 'mgmtcomtrac': 365,\n",
       " 'systemsexcellent': 366,\n",
       " 'usingsqoop': 18074,\n",
       " 'perk': 58,\n",
       " 'data-scraping': 368,\n",
       " 'sqlmobile': 369,\n",
       " 'non-traditional': 370,\n",
       " 'abilities12': 371,\n",
       " 'gwa': 372,\n",
       " 'genmod': 373,\n",
       " 'oauth': 374,\n",
       " 'marnock': 376,\n",
       " 'trackman': 377,\n",
       " 'sdlchigh-level': 378,\n",
       " 'minipig': 379,\n",
       " 'enriched': 380,\n",
       " 'agf': 384,\n",
       " 'non-volatile': 383,\n",
       " 'smg': 36080,\n",
       " 'co-taught': 37296,\n",
       " 'lehigh': 386,\n",
       " 'plattsburgh': 388,\n",
       " 'dupont': 389,\n",
       " 'utilitydetail': 390,\n",
       " 'dominion': 393,\n",
       " 'format': 392,\n",
       " 'middleburg': 394,\n",
       " 'euthanasium': 27120,\n",
       " 'dispenser': 395,\n",
       " 'branding': 396,\n",
       " 'time-keeping': 397,\n",
       " 'manugistic': 398,\n",
       " 'outlook3d': 399,\n",
       " 'sparkcontext': 400,\n",
       " 'trench': 401,\n",
       " 'minimizing': 402,\n",
       " 'munich': 404,\n",
       " 'countydevelopmental': 405,\n",
       " 'onnationwide': 406,\n",
       " 'denial': 407,\n",
       " 'costing': 409,\n",
       " '2012provided': 412,\n",
       " 'tp': 414,\n",
       " 'perfected': 415,\n",
       " 'miop': 416,\n",
       " 'label-free': 418,\n",
       " 'systemsgained': 18084,\n",
       " 'orcongressional': 9006,\n",
       " 'etcstatistical': 12651,\n",
       " 'gastonium': 419,\n",
       " 'sort-order': 420,\n",
       " 'radrequirement': 421,\n",
       " 'adjust': 422,\n",
       " 'fast-frame': 45111,\n",
       " 'servicecommunication': 423,\n",
       " 'cpq': 36085,\n",
       " 'ch': 424,\n",
       " 'quoted': 425,\n",
       " 'webcast': 426,\n",
       " 'happen': 427,\n",
       " 'scientist-lab': 428,\n",
       " 'contentiou': 430,\n",
       " 'sieble': 431,\n",
       " 'itenology': 434,\n",
       " 'configuredhadoop': 18087,\n",
       " '2016duty': 435,\n",
       " 'fed': 437,\n",
       " 'aeronautic': 438,\n",
       " 'il-12': 439,\n",
       " 'tsg101': 440,\n",
       " 'axion': 441,\n",
       " 'quarterjanuary': 443,\n",
       " 'issueswith': 444,\n",
       " 'non-degree': 446,\n",
       " 'realized': 447,\n",
       " 'pro-life': 45114,\n",
       " 'thinkingattention': 45743,\n",
       " 'administrationcore': 449,\n",
       " 'toughest': 450,\n",
       " 'physicalrehabilitation': 9007,\n",
       " 'millimeter': 451,\n",
       " 'uterine': 452,\n",
       " 'simmechanic': 453,\n",
       " 'palm': 454,\n",
       " 'balsamic': 455,\n",
       " 'offeror': 456,\n",
       " 'ideology': 457,\n",
       " 'oppositional': 6869,\n",
       " 'mopa': 458,\n",
       " 'durability': 459,\n",
       " 'pre-validation': 460,\n",
       " 'rxkinetix': 461,\n",
       " 'sofium': 462,\n",
       " 'scotwork': 464,\n",
       " 'multiplex': 465,\n",
       " 'glenview': 466,\n",
       " 'yearsjava': 36092,\n",
       " 'standard': 467,\n",
       " 'gregory': 469,\n",
       " 'websitejeremy': 470,\n",
       " 'goodyear': 471,\n",
       " 'mada': 472,\n",
       " 'ealing': 473,\n",
       " 'hd-esr': 474,\n",
       " 'oracleinternethtml': 24901,\n",
       " 'bowdoin': 476,\n",
       " 'gnu': 477,\n",
       " 'newpayment': 478,\n",
       " 'liquid-liquid': 27134,\n",
       " 'yulee': 480,\n",
       " 'moirastarted': 481,\n",
       " 'federal': 9015,\n",
       " 'targetted': 482,\n",
       " 'sign-offassisted': 483,\n",
       " 'billingsmonitored': 484,\n",
       " 'kadir': 485,\n",
       " 'viavus': 488,\n",
       " 'castleton': 487,\n",
       " 'moreprofitable': 490,\n",
       " 'truncation': 489,\n",
       " 'propelling': 492,\n",
       " '245kg': 493,\n",
       " '704': 494,\n",
       " 'gab1': 495,\n",
       " 'stressful': 496,\n",
       " 'ingenuity': 24110,\n",
       " 'offloadingnew': 497,\n",
       " 'word-processing': 18102,\n",
       " 'feedbackresult': 499,\n",
       " 'recourse': 500,\n",
       " 'presentpartner': 502,\n",
       " 'theopportunity': 503,\n",
       " 'gnp': 504,\n",
       " 'lavastorm': 505,\n",
       " 'call': 506,\n",
       " 'andvideo': 507,\n",
       " 'sympathy': 508,\n",
       " 'taiga': 509,\n",
       " 'rt': 510,\n",
       " 'capitalanalysi': 83,\n",
       " 'governed': 512,\n",
       " 'azureml': 513,\n",
       " 'revenue-per-click': 515,\n",
       " 'icfai': 45127,\n",
       " 'helpidentify': 517,\n",
       " 'pre-cursor': 518,\n",
       " 'error-free': 519,\n",
       " 'ssc': 520,\n",
       " 'murray': 521,\n",
       " 'multi-award': 522,\n",
       " 'creator': 523,\n",
       " 'teampm': 18112,\n",
       " 'rabida': 528,\n",
       " 'located': 525,\n",
       " 'co-worker': 526,\n",
       " 'wy': 529,\n",
       " 'authenticity': 530,\n",
       " 'usedexpert': 531,\n",
       " 'successfully': 532,\n",
       " '0330': 9023,\n",
       " 'reviewing': 533,\n",
       " 'subacqueo': 534,\n",
       " 'ruffle': 18114,\n",
       " 'terrace': 535,\n",
       " 'contact': 9024,\n",
       " 'notedotherwise': 9028,\n",
       " 'user-training': 537,\n",
       " 'clickstream': 53165,\n",
       " 'peril': 540,\n",
       " 'larson': 539,\n",
       " 'lighthouse': 9027,\n",
       " 'onto': 541,\n",
       " 'molybdenum': 542,\n",
       " 'fundingdecision': 27141,\n",
       " 'bsi': 543,\n",
       " 'systemsn': 45131,\n",
       " 'franceproject': 544,\n",
       " '2001july': 545,\n",
       " 'vertica': 546,\n",
       " 'mappingsystem': 549,\n",
       " 'dreamspark': 552,\n",
       " 'corresponded': 559,\n",
       " 'gato': 558,\n",
       " 'webtrend': 555,\n",
       " 'token': 557,\n",
       " 'k-8': 560,\n",
       " 'pite': 563,\n",
       " 'companiesuk': 562,\n",
       " 'devicesperformed': 569,\n",
       " 'devry': 564,\n",
       " '328': 565,\n",
       " 'protabit': 568,\n",
       " 'jh': 571,\n",
       " 'unixscript': 576,\n",
       " 'thrive': 572,\n",
       " 'practiceso': 573,\n",
       " 'majored': 575,\n",
       " 'kabul': 45138,\n",
       " 'c3': 578,\n",
       " 'editorial': 27143,\n",
       " 'theatre-level': 579,\n",
       " 'validity': 580,\n",
       " 'ppf': 581,\n",
       " 'pune': 583,\n",
       " 'aix-marseille': 587,\n",
       " 'partneringacquisitionsnegotiationstrade': 586,\n",
       " 'shaw': 588,\n",
       " 'depression': 589,\n",
       " 'afsimagevision': 590,\n",
       " 'dme': 591,\n",
       " 'internetadvertiser': 593,\n",
       " 'rule-based': 594,\n",
       " 'devise': 595,\n",
       " 'reformat': 596,\n",
       " 'opengli': 45141,\n",
       " 'coenzyme': 597,\n",
       " 'deodorant': 598,\n",
       " 'malaysium': 599,\n",
       " 're-order': 602,\n",
       " 'malibu': 603,\n",
       " 'applicationrole': 604,\n",
       " 'macrosdatabasis': 605,\n",
       " 'assayqualification': 607,\n",
       " 'usedleadershipcommunicationorganization': 608,\n",
       " '1mario': 9040,\n",
       " 'antiperspirancy': 609,\n",
       " 'linhardt': 610,\n",
       " 'picture-by-picture': 611,\n",
       " 'resale': 612,\n",
       " 'accessioned': 613,\n",
       " 'suggesting': 614,\n",
       " 'responsible': 97,\n",
       " 'usresponsibility': 619,\n",
       " 'utilise': 620,\n",
       " 'libor': 18125,\n",
       " 'issuednumerou': 622,\n",
       " '2017energypro': 623,\n",
       " 'lanham': 624,\n",
       " 'depositor': 625,\n",
       " 'smoking': 626,\n",
       " 'managementfacilitation': 18127,\n",
       " 'mendocino': 36119,\n",
       " 'renovated': 627,\n",
       " 'eua': 629,\n",
       " 'royce': 630,\n",
       " 'xrd': 631,\n",
       " 'lung': 632,\n",
       " 'revolution': 633,\n",
       " 'companycarrying': 635,\n",
       " 'sportjune': 18131,\n",
       " 'topictaking': 636,\n",
       " 'maintenanceand': 637,\n",
       " 'sleek': 21838,\n",
       " 'controlaccredited': 9046,\n",
       " 'thesis': 638,\n",
       " '70,000': 639,\n",
       " 'snapshot': 640,\n",
       " 'post-test': 641,\n",
       " 'dana': 642,\n",
       " 'xtra': 18135,\n",
       " 'uplc-utilized': 27155,\n",
       " 'multipleself-employed': 45150,\n",
       " 'comprehensively': 643,\n",
       " 'substrate': 644,\n",
       " 'wolf': 645,\n",
       " 'loaf': 647,\n",
       " 'negligent': 648,\n",
       " 'list': 649,\n",
       " 'minneanalytic': 650,\n",
       " 'navfac': 652,\n",
       " 'screenshot': 653,\n",
       " 'warehousingrequirement': 654,\n",
       " 'chai': 655,\n",
       " 'modeller': 656,\n",
       " 'intermec': 657,\n",
       " '10khz': 658,\n",
       " 'significantfeature': 659,\n",
       " 'mongodbjira': 660,\n",
       " 'geo-referenced': 661,\n",
       " 'mciip': 662,\n",
       " '3214': 663,\n",
       " 'ccp3': 110,\n",
       " 'dischargebritish': 665,\n",
       " 'and1maintain': 27159,\n",
       " 'seniormanager': 666,\n",
       " 'cyberbullying': 667,\n",
       " 'viscou': 27158,\n",
       " 'brink': 668,\n",
       " 'datan': 669,\n",
       " 'toresource': 670,\n",
       " 'impacted': 671,\n",
       " 'mongodboperating': 34657,\n",
       " 'buchanan': 672,\n",
       " 'handlingorganisation': 673,\n",
       " 'ashra': 36128,\n",
       " 'levelapmg': 675,\n",
       " 'pre-test': 677,\n",
       " 'medoption': 678,\n",
       " 'in-clas': 681,\n",
       " 'interior': 20858,\n",
       " 'zyxel': 682,\n",
       " '225m': 684,\n",
       " 'negotiationsbilling': 47927,\n",
       " 'passenglish': 685,\n",
       " 'nutrition': 686,\n",
       " 'rancher': 687,\n",
       " 'harriman': 45156,\n",
       " 'ews': 688,\n",
       " 'squarespace': 113,\n",
       " 'eyf': 689,\n",
       " 'numerou': 52196,\n",
       " '6-12': 690,\n",
       " 'exposurebioinformatic': 691,\n",
       " 'pearl': 692,\n",
       " 'ongoingprogres': 693,\n",
       " 'triatholon': 18145,\n",
       " 'on-hand': 695,\n",
       " 'vallabhbhai': 696,\n",
       " 'facilitatorexperienced': 697,\n",
       " 'missions2': 698,\n",
       " 'threatened': 700,\n",
       " 'costed': 701,\n",
       " 'infringement': 702,\n",
       " 'willask': 703,\n",
       " 'londonjune': 704,\n",
       " 'mosiero': 705,\n",
       " 'managementmanual': 706,\n",
       " 'feather': 27164,\n",
       " 'bfm': 708,\n",
       " 'batching': 711,\n",
       " 'lifespan': 710,\n",
       " 'ibioic': 712,\n",
       " 'requirement-by-requirement': 713,\n",
       " '2006epo': 714,\n",
       " 'triad': 715,\n",
       " 'alabama': 716,\n",
       " 'omniture': 717,\n",
       " 'glue': 45970,\n",
       " 'lawsstock': 718,\n",
       " 'waserstein': 52775,\n",
       " 'spanishproof-reading': 45164,\n",
       " 'predictionso': 719,\n",
       " 'servicesand': 720,\n",
       " 'linked-graph': 721,\n",
       " 'dose': 722,\n",
       " 'plese': 724,\n",
       " 'trivandrum': 725,\n",
       " 'durationipvpn': 726,\n",
       " '2000jira': 727,\n",
       " 'c260': 728,\n",
       " 'cyberlife': 45167,\n",
       " 'proof-of-concept': 729,\n",
       " 'guidechairing': 119,\n",
       " 'fiberglas': 730,\n",
       " 'confrontation': 123,\n",
       " 'detainee': 731,\n",
       " 'centerscheduler': 732,\n",
       " 'graphdatabasis': 733,\n",
       " 'preformed': 734,\n",
       " 'systemcascade': 735,\n",
       " 'chinainfrastructure': 737,\n",
       " 'cornerstone': 738,\n",
       " 'sqlplu': 739,\n",
       " 'photolithographyteaching': 741,\n",
       " 'upgrading': 742,\n",
       " 'bridgford': 743,\n",
       " 'universitt': 744,\n",
       " 'smi': 747,\n",
       " 'delicatessen': 748,\n",
       " 'day': 749,\n",
       " 'well-organised': 751,\n",
       " 'control-mrequirement': 752,\n",
       " 'dveloppement': 36143,\n",
       " 'nextech': 753,\n",
       " 'cadet': 45168,\n",
       " 'gimbal': 754,\n",
       " 'relying': 755,\n",
       " 'generatestimulu': 756,\n",
       " 'ftr': 39180,\n",
       " 'teambuilt': 757,\n",
       " 'phh': 758,\n",
       " 'simplicity': 759,\n",
       " 'analysisagile': 760,\n",
       " '2015xuber': 761,\n",
       " 'cartesi': 762,\n",
       " 'synthetases2017neurodegenerative': 764,\n",
       " 'contacting': 765,\n",
       " 'detaileddesign': 766,\n",
       " 'building': 767,\n",
       " 'sastek': 769,\n",
       " 'actionline': 770,\n",
       " 'enovium': 45170,\n",
       " 'determinant': 772,\n",
       " '208': 773,\n",
       " 'skillsproject': 775,\n",
       " \"company'spreliminary\": 776,\n",
       " 'non-material': 27175,\n",
       " '2biswajit': 778,\n",
       " '250m': 780,\n",
       " 'casino': 782,\n",
       " 'pastordeveloped': 781,\n",
       " 'dialect': 783,\n",
       " 'socializing': 784,\n",
       " 'mountbatten': 785,\n",
       " 'photographing': 786,\n",
       " 'packagei': 787,\n",
       " 'skadden': 788,\n",
       " 'inorganic': 789,\n",
       " 'clinicalfinding': 791,\n",
       " 'ruislip': 27177,\n",
       " 'minewa': 792,\n",
       " 'rheological': 794,\n",
       " 'institut': 795,\n",
       " 'trail': 796,\n",
       " 'comedic': 9077,\n",
       " 'increment': 797,\n",
       " 'puppet': 798,\n",
       " 'shift': 36146,\n",
       " 'isproject': 799,\n",
       " 'evidentiaryobjection': 800,\n",
       " 'dealer': 36147,\n",
       " 'progression': 801,\n",
       " '1,771': 27180,\n",
       " 'skillsleadership': 802,\n",
       " 'jagiellonian': 133,\n",
       " 'gromit': 805,\n",
       " 'ligament': 804,\n",
       " 'pgrouting': 9081,\n",
       " 'surf': 18161,\n",
       " '2013': 806,\n",
       " 'xpres': 807,\n",
       " 'k562': 808,\n",
       " 'cyber-physical': 36150,\n",
       " 'wascana': 809,\n",
       " 'nh': 810,\n",
       " 'competencies-effective': 811,\n",
       " 'suspicion': 812,\n",
       " 'insiebel': 813,\n",
       " 'v2v': 814,\n",
       " 'castellini': 815,\n",
       " 'staggering': 816,\n",
       " 'uscg': 817,\n",
       " 'highest-level': 818,\n",
       " 'asa': 819,\n",
       " 'ambrosium': 76,\n",
       " 'teamskill': 820,\n",
       " 'polysaccharide': 821,\n",
       " 'unsociable': 23152,\n",
       " 'marketswith': 822,\n",
       " 'cardwell': 823,\n",
       " 'cardinal': 824,\n",
       " 'draftedmemoranda': 825,\n",
       " 'iberium': 826,\n",
       " '2016academic': 827,\n",
       " 'proforma': 828,\n",
       " 'brokerage': 829,\n",
       " 'java\\\\selenium': 830,\n",
       " 'designated': 831,\n",
       " 'sparx': 832,\n",
       " 'embrace': 833,\n",
       " 'amigo': 834,\n",
       " 'nstitution': 45181,\n",
       " 'equip': 835,\n",
       " 'short-sell': 140,\n",
       " 'argo': 837,\n",
       " 'implementationmy': 838,\n",
       " 'dcka': 45184,\n",
       " 'maintenancetemperature': 839,\n",
       " 'bio-similar': 840,\n",
       " 'bucharestduty': 143,\n",
       " 'willutilise': 841,\n",
       " 'andsource': 842,\n",
       " 'tabloid': 843,\n",
       " 'crew': 844,\n",
       " 'windchill': 845,\n",
       " 'peruse': 847,\n",
       " 'lithium': 849,\n",
       " 'insurancei': 851,\n",
       " 'whitley': 852,\n",
       " 'customerized': 853,\n",
       " 'andbehavior': 18166,\n",
       " 'kong': 854,\n",
       " 'kaarya': 4493,\n",
       " 'atdd': 856,\n",
       " 'sortprovider': 857,\n",
       " 'jennison': 858,\n",
       " 'powerpointsupervisor': 859,\n",
       " 'santander': 860,\n",
       " 'bpyc': 27192,\n",
       " 'nvidium': 18168,\n",
       " 'steering': 862,\n",
       " 'danny': 864,\n",
       " 'assignmentsmulti-taskingquick': 866,\n",
       " 'hydra': 867,\n",
       " 'biomedical': 868,\n",
       " 'plasmonic': 149,\n",
       " 'next-gen': 869,\n",
       " 'conform': 870,\n",
       " 'microteaching': 871,\n",
       " 'lanchester': 872,\n",
       " 'ctp1': 873,\n",
       " 'jee': 22809,\n",
       " 'provided': 874,\n",
       " 'yamunanagar': 876,\n",
       " 'supportother': 27195,\n",
       " 'coded': 878,\n",
       " 'jsonmicrosoft': 879,\n",
       " 'marszaek': 880,\n",
       " 'omni': 881,\n",
       " 'casesanswered': 27197,\n",
       " 'restrictive': 884,\n",
       " 'research-advanced': 885,\n",
       " 'tmp': 886,\n",
       " '2014-datum': 887,\n",
       " 'despair': 888,\n",
       " 'leavey': 889,\n",
       " 'contractworking': 27204,\n",
       " 'scjp-certified': 890,\n",
       " 'bodi': 892,\n",
       " 'coexisting': 27202,\n",
       " 'vertex': 893,\n",
       " 'jba': 18174,\n",
       " 'meld': 894,\n",
       " 'nto': 896,\n",
       " 'begley': 898,\n",
       " 'ecg': 899,\n",
       " 'als70': 900,\n",
       " 'self-motivator': 901,\n",
       " 'adjustor': 904,\n",
       " 'prioitize': 903,\n",
       " 'cafepres': 46377,\n",
       " 'criminology': 906,\n",
       " 'alternativeway': 45199,\n",
       " 'ulf': 908,\n",
       " 'easyjet': 909,\n",
       " 'nanoscience': 910,\n",
       " 'unix-based': 911,\n",
       " 'andgoogle': 913,\n",
       " '2151': 53369,\n",
       " 'claimsproject': 914,\n",
       " 'semh': 3709,\n",
       " 'iparticipated': 915,\n",
       " 'tool-worklight': 916,\n",
       " 'evs1': 917,\n",
       " 'sanitation': 918,\n",
       " 'witham': 919,\n",
       " 'accomplishmentssurpas': 922,\n",
       " 'avenuenewcastle': 921,\n",
       " '3,400': 923,\n",
       " 'customer-orientatedcustomer': 924,\n",
       " 'cross-team': 925,\n",
       " '2016finance': 927,\n",
       " 'leyland': 16061,\n",
       " '10027': 928,\n",
       " 'classic': 929,\n",
       " '2017i': 45206,\n",
       " 'moc': 930,\n",
       " 'lucidly': 931,\n",
       " 'light-weightdocumentationo': 932,\n",
       " 'vara': 933,\n",
       " 'imagework': 935,\n",
       " '2005-2006': 937,\n",
       " 'bookersduty': 163,\n",
       " 'signaller': 938,\n",
       " 'functionsn': 157,\n",
       " 'rome': 939,\n",
       " 'immediately': 158,\n",
       " 'outlook98': 940,\n",
       " 'bandit': 941,\n",
       " 'diploma-purchasing': 942,\n",
       " 'cumbrium': 14760,\n",
       " 'furnishing': 944,\n",
       " 'mutate': 9103,\n",
       " 'hhsc': 945,\n",
       " 'douglas': 946,\n",
       " 'decisively': 947,\n",
       " 'angular': 949,\n",
       " 'facet': 950,\n",
       " 'welfare': 951,\n",
       " 'negociate': 953,\n",
       " 'hid': 956,\n",
       " 'casing': 955,\n",
       " 'technicaldirection': 963,\n",
       " 'evening': 957,\n",
       " 'mxd': 958,\n",
       " '2012project': 959,\n",
       " '2014human': 961,\n",
       " 'mannermentoring': 964,\n",
       " 'tsf': 965,\n",
       " 'byker': 967,\n",
       " 'edgware': 968,\n",
       " 'salestock': 36168,\n",
       " 'middlesexi': 969,\n",
       " '2016environment': 9109,\n",
       " '277': 970,\n",
       " 'circle': 971,\n",
       " 'rector': 45214,\n",
       " 'skype-based': 973,\n",
       " 'permanency': 974,\n",
       " 'gpio': 975,\n",
       " 'iqbal': 977,\n",
       " 'initialising': 978,\n",
       " 'purposejade': 979,\n",
       " 'ambiguity': 980,\n",
       " 'msdoslanguage': 981,\n",
       " 'dbt': 3645,\n",
       " 'nahrain': 982,\n",
       " 'mathematics-b': 983,\n",
       " 'documentedbusines': 984,\n",
       " 'insalesforce': 985,\n",
       " 'realtor': 986,\n",
       " 'cesmec': 49877,\n",
       " 'resubmission': 987,\n",
       " 'ex-oracle': 49695,\n",
       " ...}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(data_normalized, w2i):\n",
    "    encoded_sentence = []\n",
    "    if not isinstance(data_normalized, type(None)):\n",
    "        for token in data_normalized:\n",
    "            if not isinstance(token, type(None)):\n",
    "                for sentence in token:\n",
    "                    if not isinstance(sentence, type(None)):\n",
    "                        for w in sentence:\n",
    "                            try:\n",
    "                                encoded_sentence.append(w2i[w])\n",
    "                            except Exception:\n",
    "                                pass\n",
    "    return encoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(data_normalized, vocab=None, w2i=None, target=True):\n",
    "    if vocab is None and w2i is None:\n",
    "        w2i = build_vocab(data_normalized, target)\n",
    "\n",
    "    s = []\n",
    "    if not isinstance(data_normalized, type(None)):\n",
    "        for token in data_normalized:\n",
    "            if not isinstance(token, type(None)):\n",
    "                for sentence in token:\n",
    "                    if not isinstance(sentence, type(None)):\n",
    "                        for w in sentence:\n",
    "                            s.append(w)\n",
    "        if target:\n",
    "            s = ['<s>'] + s + ['</s>']\n",
    "        enc = encode(s, w2i)\n",
    "        data.append(enc)\n",
    "    i2w = {i: w for w, i in w2i.items()}\n",
    "    return data, w2i, i2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_all = []\n",
    "if not isinstance(data_normalized, type(None)):\n",
    "    for token in data_normalized:\n",
    "        if not isinstance(token, type(None)):\n",
    "            for sentence in token:\n",
    "                if not isinstance(sentence, type(None)):\n",
    "                    for s in sentence:\n",
    "                        data_all.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['freelance',\n",
       " 'copy',\n",
       " 'editor',\n",
       " 'of',\n",
       " '100',\n",
       " 'research',\n",
       " 'and',\n",
       " 'commercialisation',\n",
       " 'intern',\n",
       " 'hold',\n",
       " 'full',\n",
       " 'uk',\n",
       " 'driving',\n",
       " 'license',\n",
       " 'volunteer',\n",
       " 'campsite',\n",
       " 'attendant',\n",
       " 'light-scattering',\n",
       " 'technique',\n",
       " 'inkjet',\n",
       " 'printing',\n",
       " 'nmr',\n",
       " 'size-exclusion',\n",
       " 'chromatograhy',\n",
       " 'uv-visible',\n",
       " 'spectroscopy',\n",
       " 'fluorescence',\n",
       " 'post-doctoral',\n",
       " 'research',\n",
       " 'associate',\n",
       " 'team',\n",
       " 'leader',\n",
       " 'night',\n",
       " 'manager',\n",
       " 'relief',\n",
       " 'manager',\n",
       " 'supervisor',\n",
       " 'duty',\n",
       " 'manager',\n",
       " 'assistant',\n",
       " 'manager',\n",
       " 'postdoctoral',\n",
       " 'research',\n",
       " 'assistant',\n",
       " 'subharmonic',\n",
       " 'function',\n",
       " 'on',\n",
       " 'graph',\n",
       " 'differential',\n",
       " 'equation',\n",
       " 'project',\n",
       " 'within',\n",
       " 'the',\n",
       " 'course',\n",
       " 'of',\n",
       " 'programming',\n",
       " 'expertise',\n",
       " 'and',\n",
       " 'consulting',\n",
       " 'delivering',\n",
       " 'result',\n",
       " 'preparing',\n",
       " 'concise',\n",
       " 'and',\n",
       " 'logically-written',\n",
       " 'material',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'organize',\n",
       " 'and',\n",
       " 'communicate',\n",
       " 'idea',\n",
       " 'effectively',\n",
       " 'in',\n",
       " 'oral',\n",
       " 'presentation',\n",
       " 'to',\n",
       " 'small',\n",
       " 'and',\n",
       " 'large',\n",
       " 'group',\n",
       " 'meeting',\n",
       " 'deadline',\n",
       " 'and',\n",
       " 'compliance',\n",
       " 'with',\n",
       " 'the',\n",
       " 'requirement',\n",
       " 'taking',\n",
       " 'part',\n",
       " 'at',\n",
       " 'conference',\n",
       " 'belgium',\n",
       " 'france',\n",
       " 'germany',\n",
       " 'russium',\n",
       " 'etc',\n",
       " 'summer',\n",
       " 'school',\n",
       " 'austrium',\n",
       " 'usa',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'interact',\n",
       " 'with',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'culture',\n",
       " 'and',\n",
       " 'background',\n",
       " 'skill',\n",
       " 'and',\n",
       " 'achievementsit',\n",
       " 'proficiency',\n",
       " 'and',\n",
       " 'programming',\n",
       " 'skill',\n",
       " 'matlab',\n",
       " 'creating',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'wave',\n",
       " 'propagation',\n",
       " 'on',\n",
       " 'flexural',\n",
       " 'system',\n",
       " '2015',\n",
       " 'maple',\n",
       " 'microsoft',\n",
       " 'excel',\n",
       " 'scientific',\n",
       " 'calculation',\n",
       " 'for',\n",
       " 'studying',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'value',\n",
       " 'property',\n",
       " 'ofsubharmonic',\n",
       " 'function',\n",
       " 'on',\n",
       " 'graph',\n",
       " 'microsoft',\n",
       " 'visual',\n",
       " 'c',\n",
       " 'creating',\n",
       " 'of',\n",
       " 'a',\n",
       " 'student',\n",
       " 'database',\n",
       " 'comparison',\n",
       " 'of',\n",
       " 'different',\n",
       " 'sorting',\n",
       " 'methodsfor',\n",
       " 'different',\n",
       " 'sequence',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'and',\n",
       " 'finite-state',\n",
       " 'automaton',\n",
       " 'simulator',\n",
       " 'numerical',\n",
       " 'solution',\n",
       " 'ofdifferential',\n",
       " 'equation',\n",
       " 'project',\n",
       " 'within',\n",
       " 'the',\n",
       " 'course',\n",
       " 'of',\n",
       " 'programming',\n",
       " 'sql',\n",
       " 'started',\n",
       " 'to',\n",
       " 'study',\n",
       " 'coursera',\n",
       " '2016',\n",
       " 'analytical',\n",
       " 'and',\n",
       " 'critical',\n",
       " 'thinkingworking',\n",
       " 'acros',\n",
       " 'distinct',\n",
       " 'area',\n",
       " 'of',\n",
       " 'pure',\n",
       " 'and',\n",
       " 'applied',\n",
       " 'mathematics',\n",
       " 'demonstrated',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'problem',\n",
       " 'adopt',\n",
       " 'suitable',\n",
       " 'strategy',\n",
       " 'develop',\n",
       " 'new',\n",
       " 'technique',\n",
       " 'and',\n",
       " 'think',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'box',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'synthesize',\n",
       " 'large',\n",
       " 'quantity',\n",
       " 'of',\n",
       " 'complex',\n",
       " 'datum',\n",
       " 'use',\n",
       " 'logical',\n",
       " 'argument',\n",
       " 'design',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'and',\n",
       " 'consultingcollaborating',\n",
       " 'with',\n",
       " 'engineer',\n",
       " 'on',\n",
       " 'the',\n",
       " 'resent',\n",
       " 'project',\n",
       " 'and',\n",
       " 'working',\n",
       " 'a',\n",
       " 'a',\n",
       " 'tutor',\n",
       " 'presented',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'comprehend',\n",
       " 'new',\n",
       " 'material',\n",
       " 'and',\n",
       " 'subject',\n",
       " 'matter',\n",
       " 'quickly',\n",
       " 'evaluate',\n",
       " 'and',\n",
       " 'give',\n",
       " 'a',\n",
       " 'feedback',\n",
       " 'on',\n",
       " 'the',\n",
       " 'work',\n",
       " 'teach',\n",
       " 'skill',\n",
       " 'or',\n",
       " 'concept',\n",
       " 'to',\n",
       " 'resultsa',\n",
       " 'range',\n",
       " 'of',\n",
       " 'activity',\n",
       " 'including',\n",
       " 'teaching',\n",
       " 'preparing',\n",
       " 'a',\n",
       " 'phd',\n",
       " 'thesi',\n",
       " 'research',\n",
       " 'paper',\n",
       " 'conference',\n",
       " 'presenta-tion',\n",
       " 'poster',\n",
       " 'have',\n",
       " 'developed',\n",
       " 'my',\n",
       " 'written',\n",
       " 'editorial',\n",
       " 'and',\n",
       " 'public',\n",
       " 'speaking',\n",
       " 'skill',\n",
       " 'preparing',\n",
       " 'concise',\n",
       " 'and',\n",
       " 'logically-written',\n",
       " 'material',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'organize',\n",
       " 'and',\n",
       " 'communicate',\n",
       " 'idea',\n",
       " 'effectively',\n",
       " 'in',\n",
       " 'oral',\n",
       " 'presentation',\n",
       " 'to',\n",
       " 'small',\n",
       " 'and',\n",
       " 'large',\n",
       " 'group',\n",
       " 'explaining',\n",
       " 'complex',\n",
       " 'solution',\n",
       " 'to',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'from',\n",
       " 'different',\n",
       " 'background',\n",
       " 'responding',\n",
       " 'appropriately',\n",
       " 'to',\n",
       " 'positive',\n",
       " 'or',\n",
       " 'negative',\n",
       " 'feedback',\n",
       " 'meeting',\n",
       " 'deadline',\n",
       " 'and',\n",
       " 'compliance',\n",
       " 'with',\n",
       " 'the',\n",
       " 'networking',\n",
       " 'and',\n",
       " 'building',\n",
       " 'relationshipstaking',\n",
       " 'part',\n",
       " 'at',\n",
       " 'conference',\n",
       " 'belgium',\n",
       " 'france',\n",
       " 'germany',\n",
       " 'russium',\n",
       " 'etc',\n",
       " 'summer',\n",
       " 'school',\n",
       " 'austrium',\n",
       " 'usa',\n",
       " 'and',\n",
       " 'a',\n",
       " 'a',\n",
       " 'member',\n",
       " 'of',\n",
       " 'a',\n",
       " 'large',\n",
       " 'international',\n",
       " 'phd',\n",
       " 'programm',\n",
       " 'i',\n",
       " 'have',\n",
       " 'developed',\n",
       " 'my',\n",
       " 'social',\n",
       " 'skill',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'interact',\n",
       " 'with',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'culture',\n",
       " 'and',\n",
       " 'background',\n",
       " 'active',\n",
       " 'listening',\n",
       " 'and',\n",
       " 'seeing',\n",
       " 'the',\n",
       " 'point',\n",
       " 'building',\n",
       " 'of',\n",
       " 'fruitful',\n",
       " 'collaboration',\n",
       " 'with',\n",
       " 'colleague',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'contribute',\n",
       " 'expertise',\n",
       " 'and',\n",
       " 'follow',\n",
       " 'leadership',\n",
       " 'directive',\n",
       " 'at',\n",
       " 'appropriate',\n",
       " 'time',\n",
       " 'recently',\n",
       " 'obtained',\n",
       " 'a',\n",
       " 'phd',\n",
       " 'in',\n",
       " 'material',\n",
       " 'physic',\n",
       " 'from',\n",
       " 'university',\n",
       " 'college',\n",
       " 'london',\n",
       " 'ucl',\n",
       " 'uppsala',\n",
       " 'universitet',\n",
       " 'and',\n",
       " 'achieved',\n",
       " 'a',\n",
       " 'first',\n",
       " 'clas',\n",
       " 'honour',\n",
       " 'in',\n",
       " 'mscus',\n",
       " 'chemistry',\n",
       " 'from',\n",
       " 'ucl',\n",
       " 'i',\n",
       " 'have',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'laboratory',\n",
       " 'technique',\n",
       " 'computer',\n",
       " 'programming',\n",
       " 'teaching',\n",
       " 'public',\n",
       " 'engagement',\n",
       " 'international',\n",
       " 'research',\n",
       " 'collaboration',\n",
       " 'and',\n",
       " 'publication',\n",
       " 'i',\n",
       " 'am',\n",
       " 'looking',\n",
       " 'to',\n",
       " 'incorporate',\n",
       " 'strong',\n",
       " 'scientific',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'experience',\n",
       " 'into',\n",
       " 'a',\n",
       " 'material',\n",
       " 'science-related',\n",
       " 'industry',\n",
       " 'setting',\n",
       " 'work',\n",
       " 'experience',\n",
       " 'personal',\n",
       " 'assistant',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'postgraduate',\n",
       " 'research',\n",
       " 'student',\n",
       " 'who',\n",
       " 'is',\n",
       " 'currently',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'work',\n",
       " 'opportunity',\n",
       " 'whilst',\n",
       " 'studying',\n",
       " 'i',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ambitiou',\n",
       " 'person',\n",
       " 'who',\n",
       " 'ha',\n",
       " 'alway',\n",
       " 'taken',\n",
       " 'a',\n",
       " 'professional',\n",
       " 'and',\n",
       " 'responsible',\n",
       " 'approach',\n",
       " 'to',\n",
       " 'any',\n",
       " 'task',\n",
       " 'that',\n",
       " 'i',\n",
       " 'have',\n",
       " 'undertaken',\n",
       " 'i',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'teaching',\n",
       " 'part-time',\n",
       " 'on',\n",
       " 'science',\n",
       " 'undergraduate',\n",
       " 'course',\n",
       " 'along',\n",
       " 'with',\n",
       " 'demonstrating',\n",
       " 'technical',\n",
       " 'lab',\n",
       " 'skill',\n",
       " 'molecular',\n",
       " 'biologist',\n",
       " 'employability',\n",
       " 'assistant',\n",
       " 'postgraduate',\n",
       " 'student',\n",
       " 'representative',\n",
       " 'school',\n",
       " 'of',\n",
       " 'proces',\n",
       " 'and',\n",
       " 'chemical',\n",
       " 'engineering',\n",
       " 'postgraduate',\n",
       " 'student',\n",
       " 'representative',\n",
       " 'school',\n",
       " 'of',\n",
       " 'proces',\n",
       " 'and',\n",
       " 'chemical',\n",
       " 'engineering',\n",
       " 'sale',\n",
       " 'assistant',\n",
       " 'social',\n",
       " 'secretary',\n",
       " 'post-doctoral',\n",
       " 'research',\n",
       " 'associate',\n",
       " 'bank',\n",
       " 'deposit',\n",
       " 'procedure',\n",
       " 'health',\n",
       " 'and',\n",
       " 'safety',\n",
       " 'regulation',\n",
       " 'course',\n",
       " 'skill',\n",
       " 'excellent',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'skill',\n",
       " 'personnel',\n",
       " 'development',\n",
       " 'merchandising',\n",
       " 'bank',\n",
       " 'deposit',\n",
       " 'procedure',\n",
       " 'staff',\n",
       " 'training',\n",
       " 'and',\n",
       " 'development',\n",
       " 'opening',\n",
       " 'and',\n",
       " 'closing',\n",
       " 'procedure',\n",
       " 'basic',\n",
       " 'food',\n",
       " 'hygiene',\n",
       " 'certificate',\n",
       " 'health',\n",
       " 'and',\n",
       " 'safety',\n",
       " 'regulation',\n",
       " 'course',\n",
       " 'hospitality',\n",
       " 'course',\n",
       " 'national',\n",
       " 'license',\n",
       " 'certificate',\n",
       " 'local',\n",
       " 'organizer',\n",
       " 'of',\n",
       " 'a',\n",
       " 'workshop',\n",
       " 'teaching',\n",
       " 'assistant',\n",
       " 'skill',\n",
       " 'and',\n",
       " 'achievement',\n",
       " 'microsoft',\n",
       " 'visual',\n",
       " 'c',\n",
       " 'creating',\n",
       " 'of',\n",
       " 'a',\n",
       " 'student',\n",
       " 'database',\n",
       " 'comparison',\n",
       " 'of',\n",
       " 'different',\n",
       " 'sorting',\n",
       " 'method',\n",
       " 'analyze',\n",
       " 'problem',\n",
       " 'design',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'survey',\n",
       " 'comprehend',\n",
       " 'new',\n",
       " 'material',\n",
       " 'and',\n",
       " 'subject',\n",
       " 'matter',\n",
       " 'quickly',\n",
       " 'teach',\n",
       " 'skill',\n",
       " 'or',\n",
       " 'concept',\n",
       " 'to',\n",
       " 'other',\n",
       " 'explaining',\n",
       " 'complex',\n",
       " 'solution',\n",
       " 'to',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'from',\n",
       " 'different',\n",
       " 'background',\n",
       " 'communication',\n",
       " 'networking',\n",
       " 'and',\n",
       " 'building',\n",
       " 'relationship',\n",
       " 'gcse',\n",
       " 'science',\n",
       " 'teacher',\n",
       " 'saturday',\n",
       " 'school',\n",
       " 'chemical',\n",
       " 'engineer',\n",
       " 'consultant',\n",
       " 'clinical',\n",
       " 'psychologist',\n",
       " 'bartender',\n",
       " 'waitres',\n",
       " 'i',\n",
       " 'consider',\n",
       " 'myself',\n",
       " 'to',\n",
       " 'be',\n",
       " 'determined',\n",
       " 'hard-working',\n",
       " 'hand',\n",
       " 'on',\n",
       " 'and',\n",
       " 'a',\n",
       " 'reliable',\n",
       " 'worker',\n",
       " 'and',\n",
       " 'a',\n",
       " 'good',\n",
       " 'time',\n",
       " 'keeper',\n",
       " 'i',\n",
       " 'have',\n",
       " 'good',\n",
       " 'communication',\n",
       " 'skill',\n",
       " 'i',\n",
       " 'am',\n",
       " 'very',\n",
       " 'confident',\n",
       " 'when',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'other',\n",
       " 'and',\n",
       " 'can',\n",
       " 'work',\n",
       " 'well',\n",
       " 'either',\n",
       " 'a',\n",
       " 'part',\n",
       " 'of',\n",
       " 'a',\n",
       " 'team',\n",
       " 'and',\n",
       " 'alone',\n",
       " 'using',\n",
       " 'my',\n",
       " 'own',\n",
       " 'initiative',\n",
       " 'i',\n",
       " 'welcome',\n",
       " 'new',\n",
       " 'challenge',\n",
       " 'with',\n",
       " 'open',\n",
       " 'arm',\n",
       " 'and',\n",
       " 'am',\n",
       " 'willing',\n",
       " 'to',\n",
       " 'undertake',\n",
       " 'further',\n",
       " 'training',\n",
       " 'a',\n",
       " 'necessary',\n",
       " 'to',\n",
       " 'enhance',\n",
       " 'my',\n",
       " 'career',\n",
       " 'have',\n",
       " 'extensive',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'and',\n",
       " 'generally',\n",
       " 'enjoy',\n",
       " 'helping',\n",
       " 'person',\n",
       " 'the',\n",
       " 'social',\n",
       " 'skill',\n",
       " 'i',\n",
       " 'have',\n",
       " 'developed',\n",
       " 'through',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'work',\n",
       " 'and',\n",
       " 'socializing',\n",
       " 'with',\n",
       " 'other',\n",
       " 'inside',\n",
       " 'and',\n",
       " 'outside',\n",
       " 'of',\n",
       " 'the',\n",
       " 'workplace',\n",
       " 'have',\n",
       " 'shaped',\n",
       " 'me',\n",
       " 'into',\n",
       " 'a',\n",
       " 'confident',\n",
       " 'outgoing',\n",
       " 'and',\n",
       " 'adaptable',\n",
       " 'employee',\n",
       " 'and',\n",
       " 'i',\n",
       " 'believe',\n",
       " 'i',\n",
       " 'can',\n",
       " 'transfer',\n",
       " 'and',\n",
       " 'apply',\n",
       " 'the',\n",
       " 'skill',\n",
       " 'and',\n",
       " 'knowledge',\n",
       " 'to',\n",
       " 'any',\n",
       " 'position',\n",
       " 'i',\n",
       " 'aim',\n",
       " 'to',\n",
       " 'obtain',\n",
       " 'freelance',\n",
       " 'graphic',\n",
       " 'and',\n",
       " 'page',\n",
       " 'designer',\n",
       " 'french',\n",
       " 'basic',\n",
       " 'adobe',\n",
       " 'creative',\n",
       " 'suite',\n",
       " 'cs',\n",
       " 'software',\n",
       " 'lecturer',\n",
       " 'in',\n",
       " 'international',\n",
       " 'busines',\n",
       " 'busines',\n",
       " 'economic',\n",
       " 'doctoral',\n",
       " 'researcher',\n",
       " 'doctoral',\n",
       " 'researcher',\n",
       " 'skill',\n",
       " 'expertise',\n",
       " 'warehouse',\n",
       " 'operative',\n",
       " 'support',\n",
       " 'worker',\n",
       " 'part-time',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'phd',\n",
       " 'graduate',\n",
       " 'in',\n",
       " 'electrical',\n",
       " 'and',\n",
       " 'electronic',\n",
       " 'engineering',\n",
       " 'and',\n",
       " 'wish',\n",
       " 'to',\n",
       " 'find',\n",
       " 'a',\n",
       " 'job',\n",
       " 'my',\n",
       " 'research',\n",
       " 'wa',\n",
       " 'on',\n",
       " 'video',\n",
       " 'coding',\n",
       " 'algorithm',\n",
       " 'and',\n",
       " 'gaze',\n",
       " 'location',\n",
       " 'prediction',\n",
       " 'during',\n",
       " 'i',\n",
       " 'have',\n",
       " 'developed',\n",
       " 'solid',\n",
       " 'skill',\n",
       " 'on',\n",
       " 'image',\n",
       " 'processing',\n",
       " 'video',\n",
       " 'compression',\n",
       " 'statistical',\n",
       " 'analysi',\n",
       " 'and',\n",
       " 'programming',\n",
       " 'my',\n",
       " 'time',\n",
       " 'management',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'and',\n",
       " 'communication',\n",
       " 'skill',\n",
       " 'have',\n",
       " 'been',\n",
       " 'practised',\n",
       " 'i',\n",
       " 'have',\n",
       " 'achieved',\n",
       " 'first',\n",
       " 'clas',\n",
       " 'during',\n",
       " 'education',\n",
       " 'and',\n",
       " 'got',\n",
       " 'the',\n",
       " 'best',\n",
       " 'publication',\n",
       " 'in',\n",
       " 'my',\n",
       " 'phd',\n",
       " 'field',\n",
       " 'currently',\n",
       " 'i',\n",
       " 'have',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'field',\n",
       " 'like',\n",
       " 'pattern',\n",
       " 'recognition',\n",
       " 'datum',\n",
       " 'analysi',\n",
       " 'real-time',\n",
       " 'programming',\n",
       " 'and',\n",
       " 'software',\n",
       " 'engineering',\n",
       " 'i',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'find',\n",
       " 'a',\n",
       " 'job',\n",
       " 'in',\n",
       " 'the',\n",
       " 'industry',\n",
       " 'and',\n",
       " 'have',\n",
       " 'a',\n",
       " 'good',\n",
       " 'start',\n",
       " 'of',\n",
       " 'my',\n",
       " 'career',\n",
       " 'self',\n",
       " 'employed',\n",
       " 'web',\n",
       " 'designer',\n",
       " 'i',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'in',\n",
       " 'the',\n",
       " 'final',\n",
       " 'stage',\n",
       " 'of',\n",
       " 'a',\n",
       " 'phd',\n",
       " 'in',\n",
       " 'polymer',\n",
       " 'chemistry',\n",
       " 'which',\n",
       " 'involved',\n",
       " 'the',\n",
       " 'formulation',\n",
       " 'synthesi',\n",
       " 'and',\n",
       " 'analysi',\n",
       " 'of',\n",
       " 'several',\n",
       " 'elastomeric',\n",
       " 'species',\n",
       " 'including',\n",
       " 'polyacrylate',\n",
       " 'polyurethane',\n",
       " 'and',\n",
       " 'styrene-butadiene',\n",
       " 'rubber',\n",
       " 'i',\n",
       " 'have',\n",
       " 'found',\n",
       " 'thi',\n",
       " 'degree',\n",
       " 'course',\n",
       " 'both',\n",
       " 'challenging',\n",
       " 'and',\n",
       " 'rewarding',\n",
       " 'a',\n",
       " 'i',\n",
       " 'am',\n",
       " 'keen',\n",
       " 'to',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'and',\n",
       " 'develop',\n",
       " 'new',\n",
       " 'skill',\n",
       " 'however',\n",
       " 'i',\n",
       " 'have',\n",
       " 'realised',\n",
       " 'that',\n",
       " 'i',\n",
       " 'wish',\n",
       " 'to',\n",
       " 'pursue',\n",
       " 'a',\n",
       " 'laboratory',\n",
       " 'based',\n",
       " 'career',\n",
       " 'in',\n",
       " 'chemistry',\n",
       " 'outside',\n",
       " 'of',\n",
       " 'academium',\n",
       " 'i',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'an',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'contribute',\n",
       " 'in',\n",
       " 'the',\n",
       " 'research',\n",
       " 'and',\n",
       " 'development',\n",
       " 'of',\n",
       " 'polymeric',\n",
       " 'material',\n",
       " 'litigation',\n",
       " 'executive',\n",
       " ...]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sdasd', 'asdasd', 'sdasdas']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '''sdasd asdasd sdasdas'''\n",
    "\n",
    "s = a.split()\n",
    "\n",
    "s = ['<s>'] + s + ['</s>']\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def build_vocab(data_word_tokenized, target):\n",
    "#     vocab = set()\n",
    "#     for token in data_word_tokenized:\n",
    "#         for sent in token:\n",
    "#             if not isinstance(sent, type(None)):\n",
    "#                 for word in sent:\n",
    "#                     vocab.add(word)\n",
    "            \n",
    "#     if target:\n",
    "#         w2i = {w: np.int32(i+2) for i, w in enumerate(vocab)}\n",
    "#         w2i['<s>'], w2i['</s>'] = np.int32(0), np.int32(1)\n",
    "#     else:\n",
    "#         w2i = {w: np.int32(i) for i, w in enumerate(vocab)}\n",
    "\n",
    "#     return w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_normalized = data_word_tokenized.map(lambda l: map(lambda wl: map(lambda w: nltk.stem.PorterStemmer.NLTK_EXTENSIONS(w) if w in wl and not isinstance(w, type(None)) else wl.remove(w), wl), l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-7f1cfeb94f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-82eefccd2ba1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(w)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_word_tokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPorterStemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLTK_EXTENSIONS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwl\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mwl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "ree = re.compile(r'(\\'\\w)')\n",
    "wl = list()\n",
    "\n",
    "for i in data_normalized:\n",
    "    for j in i:\n",
    "        if not isinstance(j, type(None)):\n",
    "            for k in j:\n",
    "                for l in k:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ree = re.compile(r'(\\'\\w)')\n",
    "wl = list()\n",
    "\n",
    "for i in normalize(data_word_tokenized,**tokenizer_prefs):\n",
    "    for j in i:\n",
    "        if not isinstance(j, type(None)):\n",
    "            for k in j:\n",
    "                if not isinstance(k, type(None)):\n",
    "                    if re.match(ree, k):\n",
    "                        ree.sub('', k)\n",
    "                    if len(k.strip().strip('.').strip(',')) > 1:\n",
    "                        wl.append((k))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeNoneTypes(lst):\n",
    "    return [i for i in lst if type(i) is not type(None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(data_word_tokenized, **kwargs):\n",
    "    tokenizer = kwargs['tokenizer']\n",
    "    normalizer = kwargs['token_format']\n",
    "    spelling = kwargs['spell_correct']\n",
    "    \n",
    "    data_normalized = data_word_tokenized.map(lambda l: map(lambda wl: removeNoneTypes(wl), l))\n",
    "    data_normalized = data_normalized.map(lambda l: map(lambda w: w.singularize(), l))\n",
    "    \n",
    "    # filter out 'bad' words, normalize good ones\n",
    "    # w if w not in self.stopWords else wl.remove(w)\n",
    "    data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w in stopWords else w, wl), l))\n",
    "    data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'s' else w, wl), l))\n",
    "    data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'d' else w, wl), l))\n",
    " \n",
    "     # remove tokens with length 1\n",
    "#     ree = re.compile(r'(\\'\\w)')\n",
    "#     rlen = len(data_normalized)\n",
    "#     tmp = data_normalized.copy()\n",
    "# #     tmp.reset_index(drop=True)\n",
    "#     for indx in tmp.index:\n",
    "         wl_coll = list()\n",
    "         for i in normalize(data_word_tokenized,**tokenizer_prefs):\n",
    "            for j in i:\n",
    "                if not isinstance(j, type(None)):\n",
    "                    for k in j:\n",
    "                        if not isinstance(k, type(None)):\n",
    "                            if re.match(ree, i):\n",
    "                                ree.sub('', i)\n",
    "                            if len(i.strip().strip('.').strip(',')) > 1:\n",
    "                                wl.append((i))\n",
    "                    wl_coll.append(WordList(wl))\n",
    "            data_normalized[indx] = wl_col\n",
    "            del tmp\n",
    "\n",
    "    # stemming\n",
    "    data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: nltk.stemmer.stem(w) if w in wl and not isinstance(w, types.NoneType) else wl.remove(w), wl), l))\n",
    "\n",
    "    data_word_tokenized= tokenize_words('value_char', **tokenizer_prefs)\n",
    "    \n",
    "    return data_word_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "tokenizer  =   RegexpTokenizer(pattern=r'\\w+')\n",
    "stemmer    =   nltk.stem.PorterStemmer.NLTK_EXTENSIONS\n",
    "lemmatize  =   nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <map object at 0x7fbaa7e44550>\n",
       "1        <map object at 0x7fbaa7e445c0>\n",
       "2        <map object at 0x7fbaa7e44630>\n",
       "3        <map object at 0x7fbaa7e446d8>\n",
       "4        <map object at 0x7fbaa7e44780>\n",
       "6        <map object at 0x7fbaa7e44828>\n",
       "7        <map object at 0x7fbaa7e448d0>\n",
       "8        <map object at 0x7fbaa7e44978>\n",
       "9        <map object at 0x7fbaa7e44a20>\n",
       "10       <map object at 0x7fbaa7e44ac8>\n",
       "11       <map object at 0x7fbaa7e44b70>\n",
       "12       <map object at 0x7fbaa7e44c18>\n",
       "13       <map object at 0x7fbaa7e44cc0>\n",
       "14       <map object at 0x7fbaa7e44d68>\n",
       "18       <map object at 0x7fbaa7e44e10>\n",
       "19       <map object at 0x7fbaa7e44eb8>\n",
       "21       <map object at 0x7fbaa7e44f60>\n",
       "22       <map object at 0x7fbaa7e46048>\n",
       "23       <map object at 0x7fbaa7e460f0>\n",
       "24       <map object at 0x7fbaa7e46198>\n",
       "25       <map object at 0x7fbaa7e46240>\n",
       "29       <map object at 0x7fbaa7e462e8>\n",
       "30       <map object at 0x7fbaa7e46390>\n",
       "31       <map object at 0x7fbaa7e46438>\n",
       "32       <map object at 0x7fbaa7e464e0>\n",
       "33       <map object at 0x7fbaa7e46588>\n",
       "34       <map object at 0x7fbaa7e46630>\n",
       "35       <map object at 0x7fbaa7e466d8>\n",
       "36       <map object at 0x7fbaa7e46780>\n",
       "37       <map object at 0x7fbaa7e46828>\n",
       "                      ...              \n",
       "26744    <map object at 0x7fbaa778ceb8>\n",
       "26745    <map object at 0x7fbaa778cf60>\n",
       "26746    <map object at 0x7fbaa778e048>\n",
       "26747    <map object at 0x7fbaa778e0f0>\n",
       "26748    <map object at 0x7fbaa778e198>\n",
       "26749    <map object at 0x7fbaa778e240>\n",
       "26751    <map object at 0x7fbaa778e2e8>\n",
       "26752    <map object at 0x7fbaa778e390>\n",
       "26753    <map object at 0x7fbaa778e438>\n",
       "26754    <map object at 0x7fbaa778e4e0>\n",
       "26755    <map object at 0x7fbaa778e588>\n",
       "26756    <map object at 0x7fbaa778e630>\n",
       "26757    <map object at 0x7fbaa778e6d8>\n",
       "26758    <map object at 0x7fbaa778e780>\n",
       "26759    <map object at 0x7fbaa778e828>\n",
       "26760    <map object at 0x7fbaa778e8d0>\n",
       "26761    <map object at 0x7fbaa778e978>\n",
       "26762    <map object at 0x7fbaa778ea20>\n",
       "26763    <map object at 0x7fbaa778eac8>\n",
       "26764    <map object at 0x7fbaa778eb70>\n",
       "26765    <map object at 0x7fbaa778ec18>\n",
       "26767    <map object at 0x7fbaa778ecc0>\n",
       "26768    <map object at 0x7fbaa778ed68>\n",
       "26769    <map object at 0x7fbaa778ee10>\n",
       "26770    <map object at 0x7fbaa778eeb8>\n",
       "26771    <map object at 0x7fbaa778ef60>\n",
       "26772    <map object at 0x7fbaa7790048>\n",
       "26773    <map object at 0x7fbaa77900f0>\n",
       "26774    <map object at 0x7fbaa7790198>\n",
       "26775    <map object at 0x7fbaa7790240>\n",
       "Name: value_char, Length: 22845, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(data_word_tokenized,**tokenizer_prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ree = re.compile(r'(\\'\\w)')\n",
    "wl = list()\n",
    "\n",
    "for i in normalize(data_word_tokenized,**tokenizer_prefs):\n",
    "    for j in i:\n",
    "        if not isinstance(j, type(None)):\n",
    "            for k in j:\n",
    "                if not isinstance(k, type(None)):\n",
    "                    if re.match(ree, k):\n",
    "                        ree.sub('', k)\n",
    "                    if len(k.strip().strip('.').strip(',')) > 1:\n",
    "                        wl.append((k))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mitcham',\n",
       " 'guest',\n",
       " 'lecturer',\n",
       " 'crewe',\n",
       " 'pencari',\n",
       " 'kerja',\n",
       " 'an',\n",
       " 'ambitious',\n",
       " 'and',\n",
       " 'hardworking',\n",
       " 'individual',\n",
       " 'who',\n",
       " 'is',\n",
       " 'motivated',\n",
       " 'by',\n",
       " 'challenge',\n",
       " 'and',\n",
       " 'is',\n",
       " 'passionate',\n",
       " 'to',\n",
       " 'be',\n",
       " 'successful',\n",
       " 'inventor',\n",
       " 'on',\n",
       " 'four',\n",
       " 'patents',\n",
       " 'excellent',\n",
       " 'communicator',\n",
       " 'strong',\n",
       " 'planning',\n",
       " 'organisational',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'skills',\n",
       " 'with',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'successfully',\n",
       " 'analyse',\n",
       " 'and',\n",
       " 'assimilate',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'complex',\n",
       " 'and',\n",
       " 'disparate',\n",
       " 'information',\n",
       " 'good',\n",
       " 'time',\n",
       " 'management',\n",
       " 'enjoys',\n",
       " 'working',\n",
       " 'under',\n",
       " 'pressure',\n",
       " 'and',\n",
       " 'to',\n",
       " 'deadlines',\n",
       " 'either',\n",
       " 'individually',\n",
       " 'or',\n",
       " 'as',\n",
       " 'part',\n",
       " 'of',\n",
       " 'team',\n",
       " 'conversational',\n",
       " 'german',\n",
       " 'part',\n",
       " 'time',\n",
       " 'lecturing',\n",
       " 'and',\n",
       " 'lab',\n",
       " 'demonstrator',\n",
       " 'project',\n",
       " 'evaluation',\n",
       " 'and',\n",
       " 'responsible',\n",
       " 'innovation',\n",
       " 'intern',\n",
       " 'computer',\n",
       " 'skills-',\n",
       " 'good',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'it',\n",
       " 'and',\n",
       " 'confident',\n",
       " 'in',\n",
       " 'using',\n",
       " 'all',\n",
       " 'office',\n",
       " 'full',\n",
       " 'uk',\n",
       " 'driving',\n",
       " 'license',\n",
       " 'dewsbury',\n",
       " 'research',\n",
       " 'intern',\n",
       " 'micro',\n",
       " 'bio',\n",
       " 'nanofluidics',\n",
       " 'unit',\n",
       " 'attendant',\n",
       " 'lab',\n",
       " 'skills',\n",
       " 'spectroscopy',\n",
       " 'infra-red',\n",
       " 'spectroscopy',\n",
       " 'surface-tensiometry',\n",
       " 'conductivity',\n",
       " 'electron',\n",
       " 'microscopy',\n",
       " 'polymerisation',\n",
       " 'techniques',\n",
       " 'inc.',\n",
       " 'emulsion',\n",
       " 'dispersion',\n",
       " 'polymerisation',\n",
       " 'rheology',\n",
       " 'micro-piv',\n",
       " 'microfluidics',\n",
       " 'skillslight-scattering',\n",
       " 'techniques',\n",
       " 'inkjet',\n",
       " 'printing',\n",
       " 'nmr',\n",
       " 'size-exclusion',\n",
       " 'chromatograhy',\n",
       " 'uv-visible',\n",
       " 'spectroscopy',\n",
       " 'fluorescencelab',\n",
       " 'skills',\n",
       " 'spectroscopy',\n",
       " 'infra-red',\n",
       " 'spectroscopy',\n",
       " 'surface-tensiometry',\n",
       " 'conductivity',\n",
       " 'electron',\n",
       " 'microscopy',\n",
       " 'polymerisation',\n",
       " 'techniques',\n",
       " 'inc.',\n",
       " 'emulsion',\n",
       " 'dispersion',\n",
       " 'polymerisation',\n",
       " 'rheology',\n",
       " 'micro-piv',\n",
       " 'microfluidicscomputer',\n",
       " 'ms',\n",
       " 'office',\n",
       " 'ltex',\n",
       " 'inkscape',\n",
       " 'image',\n",
       " 'software',\n",
       " 'imagej',\n",
       " 'chembiooffice',\n",
       " 'origin',\n",
       " 'and',\n",
       " 'blender',\n",
       " 'basic',\n",
       " 'team',\n",
       " 'leader',\n",
       " 'night',\n",
       " 'manager',\n",
       " 'london',\n",
       " 'excellent',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'skills',\n",
       " 'personnel',\n",
       " 'development',\n",
       " 'merchandising',\n",
       " 'staff',\n",
       " 'training',\n",
       " 'and',\n",
       " 'development',\n",
       " 'liverpool',\n",
       " 'postdoctoral',\n",
       " 'research',\n",
       " 'assistant',\n",
       " 'it',\n",
       " 'proficiency',\n",
       " 'and',\n",
       " 'programming',\n",
       " 'skills',\n",
       " 'matlab',\n",
       " 'creating',\n",
       " 'simulations',\n",
       " 'of',\n",
       " 'wave',\n",
       " 'propagation',\n",
       " 'on',\n",
       " 'flexural',\n",
       " 'systems',\n",
       " '2015',\n",
       " 'for',\n",
       " 'different',\n",
       " 'sequences',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'and',\n",
       " 'finite-state',\n",
       " 'automaton',\n",
       " 'simulators',\n",
       " 'numerical',\n",
       " 'solution',\n",
       " 'of',\n",
       " 'sql',\n",
       " 'started',\n",
       " 'to',\n",
       " 'study',\n",
       " 'coursera',\n",
       " '2016-',\n",
       " 'analytical',\n",
       " 'and',\n",
       " 'critical',\n",
       " 'thinking',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'synthesize',\n",
       " 'large',\n",
       " 'quantities',\n",
       " 'of',\n",
       " 'complex',\n",
       " 'data',\n",
       " 'range',\n",
       " 'of',\n",
       " 'activities',\n",
       " 'including',\n",
       " 'teaching',\n",
       " 'preparing',\n",
       " 'phd',\n",
       " 'thesis',\n",
       " 'research',\n",
       " 'papers',\n",
       " 'conference',\n",
       " 'presenta-',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'contribute',\n",
       " 'expertise',\n",
       " 'and',\n",
       " 'follow',\n",
       " 'leadership',\n",
       " 'directives',\n",
       " 'at',\n",
       " 'appropriate',\n",
       " 'times',\n",
       " 'marple',\n",
       " 'cheshire',\n",
       " 'uk',\n",
       " 'chemical',\n",
       " 'engineer',\n",
       " 'with',\n",
       " 'significant',\n",
       " 'experience',\n",
       " 'of',\n",
       " 'working',\n",
       " 'as',\n",
       " 'part',\n",
       " 'of',\n",
       " 'team',\n",
       " 'and',\n",
       " 'individually',\n",
       " 'in',\n",
       " 'timeline',\n",
       " 'driven',\n",
       " 'highly',\n",
       " 'pressurised',\n",
       " 'industrial',\n",
       " 'and',\n",
       " 'academic',\n",
       " 'environments',\n",
       " 'this',\n",
       " 'experience',\n",
       " 'has',\n",
       " 'been',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'large',\n",
       " 'range',\n",
       " 'of',\n",
       " 'projects',\n",
       " 'in',\n",
       " 'chemical',\n",
       " 'engineering',\n",
       " 'science',\n",
       " 'and',\n",
       " 'biotechnology',\n",
       " 'following',\n",
       " 'several',\n",
       " 'bachelor',\n",
       " 'degrees',\n",
       " 'and',\n",
       " 'phd',\n",
       " 'in',\n",
       " 'chemical',\n",
       " 'engineering',\n",
       " 'this',\n",
       " 'has',\n",
       " 'manifested',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'two',\n",
       " 'patent',\n",
       " 'applications',\n",
       " 'of',\n",
       " 'which',\n",
       " 'am',\n",
       " 'co-inventor',\n",
       " 'this',\n",
       " 'industrial',\n",
       " 'experience',\n",
       " 'combined',\n",
       " 'with',\n",
       " 'postgraduate',\n",
       " 'training',\n",
       " 'has',\n",
       " 'been',\n",
       " 'in',\n",
       " 'multi-disciplinary',\n",
       " 'environments',\n",
       " 'enabling',\n",
       " 'effective',\n",
       " 'communication',\n",
       " 'with',\n",
       " 'people',\n",
       " 'from',\n",
       " 'very',\n",
       " 'different',\n",
       " 'technical',\n",
       " 'and',\n",
       " 'non-technical',\n",
       " 'backgrounds',\n",
       " 'also',\n",
       " 'currently',\n",
       " 'in',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'applying',\n",
       " 'for',\n",
       " 'chartership',\n",
       " 'london',\n",
       " 'registered',\n",
       " 'manager',\n",
       " 'london',\n",
       " 'demonstrator',\n",
       " 'chess',\n",
       " 'teacher',\n",
       " 'london',\n",
       " 'persian',\n",
       " 'native',\n",
       " 'general',\n",
       " 'operation',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'benfleet',\n",
       " 'matching',\n",
       " 'programming',\n",
       " 'matlab',\n",
       " 'scilab',\n",
       " 'shell',\n",
       " 'script',\n",
       " 'proficient',\n",
       " 'in',\n",
       " 'the',\n",
       " 'development',\n",
       " 'in',\n",
       " 'windows',\n",
       " 'and',\n",
       " 'linux',\n",
       " 'eigen',\n",
       " 'boost',\n",
       " 'opengl',\n",
       " 'etc',\n",
       " 'principal',\n",
       " 'scientist',\n",
       " 'sheffield',\n",
       " 'laboratory',\n",
       " 'demonstrator',\n",
       " 'legal',\n",
       " 'researcher',\n",
       " 'freelance',\n",
       " 'writer',\n",
       " 'all',\n",
       " 'areas',\n",
       " 'trainee',\n",
       " 'paralegal',\n",
       " 'have',\n",
       " 'excellent',\n",
       " 'skills',\n",
       " 'gained',\n",
       " 'through',\n",
       " 'regularly',\n",
       " 'using',\n",
       " 'window',\n",
       " 'based',\n",
       " 'applications',\n",
       " 'such',\n",
       " 'as',\n",
       " 'microsoft',\n",
       " 'word',\n",
       " 'microsoft',\n",
       " 'excel',\n",
       " 'microsoft',\n",
       " 'powerpoint',\n",
       " 'computer',\n",
       " 'and',\n",
       " 'language',\n",
       " 'skills',\n",
       " 'have',\n",
       " 'excellent',\n",
       " 'skills',\n",
       " 'gained',\n",
       " 'through',\n",
       " 'regularly',\n",
       " 'using',\n",
       " 'window',\n",
       " 'based',\n",
       " 'applications',\n",
       " 'such',\n",
       " 'as',\n",
       " 'microsoft',\n",
       " 'word',\n",
       " 'microsoft',\n",
       " 'excel',\n",
       " 'microsoft',\n",
       " 'powerpoint',\n",
       " 'have',\n",
       " 'obtained',\n",
       " 'certificate',\n",
       " 'in',\n",
       " 'key',\n",
       " 'skills',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'at',\n",
       " 'level',\n",
       " 'can',\n",
       " 'read',\n",
       " 'speak',\n",
       " 'and',\n",
       " 'write',\n",
       " 'in',\n",
       " 'french',\n",
       " 'at',\n",
       " 'an',\n",
       " 'advanced',\n",
       " 'level',\n",
       " 'can',\n",
       " 'speak',\n",
       " 'my',\n",
       " 'mother',\n",
       " 'tongue',\n",
       " 'language',\n",
       " 'punjabi',\n",
       " 'fluently',\n",
       " 'currently',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'activities',\n",
       " 'am',\n",
       " 'and',\n",
       " 'enthusiastic',\n",
       " 'runner',\n",
       " 'am',\n",
       " 'greatly',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'mountain',\n",
       " 'climbing',\n",
       " 'as',\n",
       " 'recenlty',\n",
       " 'discovered',\n",
       " 'when',\n",
       " 'climbing',\n",
       " 'mount',\n",
       " 'sinai',\n",
       " 'in',\n",
       " 'north',\n",
       " 'africa',\n",
       " 'like',\n",
       " 'travelling',\n",
       " 'and',\n",
       " 'have',\n",
       " 'recently',\n",
       " 'been',\n",
       " 'backpacking',\n",
       " 'in',\n",
       " 'the',\n",
       " 'artic',\n",
       " 'circle',\n",
       " 'languages',\n",
       " 'and',\n",
       " 'different',\n",
       " 'cultures',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'greatly',\n",
       " 'am',\n",
       " 'first',\n",
       " 'aider',\n",
       " 'hold',\n",
       " 'full',\n",
       " 'clean',\n",
       " 'driving',\n",
       " 'like',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'up',\n",
       " 'to',\n",
       " 'date',\n",
       " 'with',\n",
       " 'current',\n",
       " 'affairs',\n",
       " 'and',\n",
       " 'legal',\n",
       " 'issues',\n",
       " 'birmingham',\n",
       " 'consultant',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'developer',\n",
       " 'credit',\n",
       " 'risk',\n",
       " 'analyst',\n",
       " 'lavastorm',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'with',\n",
       " 'business',\n",
       " 'intelligence',\n",
       " 'tools',\n",
       " 'such',\n",
       " 'as',\n",
       " 'qlikview',\n",
       " 'tableau',\n",
       " 'and',\n",
       " 'omniscope',\n",
       " 'cheltenham',\n",
       " 'adel',\n",
       " 'ia',\n",
       " 'marketing',\n",
       " 'manager',\n",
       " 'emea',\n",
       " 'norwich',\n",
       " 'associate',\n",
       " 'producer',\n",
       " 'production',\n",
       " 'manager',\n",
       " 'art',\n",
       " 'coordinator',\n",
       " 'associate',\n",
       " 'tutor',\n",
       " 'exam',\n",
       " 'invigilation',\n",
       " 'case',\n",
       " 'manager',\n",
       " 'job',\n",
       " 'seeker',\n",
       " 'member',\n",
       " 'of',\n",
       " 'school',\n",
       " 'executive',\n",
       " 'nottingham',\n",
       " 'talent',\n",
       " 'match',\n",
       " 'sheffield',\n",
       " 'city',\n",
       " 'region',\n",
       " 'programme',\n",
       " 'administrator',\n",
       " 'american',\n",
       " 'fork',\n",
       " 'ut',\n",
       " 'independent',\n",
       " 'consultant',\n",
       " 'global',\n",
       " 'health',\n",
       " 'sector',\n",
       " 'capacity',\n",
       " 'builder',\n",
       " 'lecturer',\n",
       " 'in',\n",
       " 'project',\n",
       " 'management',\n",
       " 'creative',\n",
       " 'and',\n",
       " 'well-rounded',\n",
       " 'graduate',\n",
       " 'with',\n",
       " 'first',\n",
       " 'class',\n",
       " 'honours',\n",
       " 'degree',\n",
       " 'in',\n",
       " 'english',\n",
       " 'and',\n",
       " 'creativewriting',\n",
       " 'and',\n",
       " 'masters',\n",
       " 'in',\n",
       " 'medical',\n",
       " 'humanities',\n",
       " 'currently',\n",
       " 'completing',\n",
       " 'phd',\n",
       " 'significant',\n",
       " 'experienceof',\n",
       " 'managing',\n",
       " 'and',\n",
       " 'motivating',\n",
       " 'large',\n",
       " 'teams',\n",
       " 'in',\n",
       " 'the',\n",
       " 'volunteering',\n",
       " 'and',\n",
       " 'charitable',\n",
       " 'sectors',\n",
       " 'exceptionalknowledge',\n",
       " 'of',\n",
       " 'the',\n",
       " 'social',\n",
       " 'cultural',\n",
       " 'legislative',\n",
       " 'and',\n",
       " 'personal',\n",
       " 'issues',\n",
       " 'those',\n",
       " 'with',\n",
       " 'disabilities',\n",
       " 'face',\n",
       " 'attentive',\n",
       " 'todetail',\n",
       " 'with',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'freelance',\n",
       " 'editing',\n",
       " 'and',\n",
       " 'copywriting',\n",
       " 'confident',\n",
       " 'and',\n",
       " 'enthusiastic',\n",
       " 'with',\n",
       " 'excellentcommunication',\n",
       " 'skills',\n",
       " 'natural',\n",
       " 'leader',\n",
       " 'and',\n",
       " 'hands',\n",
       " 'on',\n",
       " 'team',\n",
       " 'worker',\n",
       " 'who',\n",
       " 'is',\n",
       " 'effective',\n",
       " 'at',\n",
       " 'time',\n",
       " 'managementand',\n",
       " 'presentations',\n",
       " 'to',\n",
       " 'groups',\n",
       " 'thrives',\n",
       " 'on',\n",
       " 'new',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'goals',\n",
       " 'part',\n",
       " 'time',\n",
       " 'lecturing',\n",
       " 'and',\n",
       " 'lab',\n",
       " 'demonstrator',\n",
       " 'leicestershire',\n",
       " 'uk',\n",
       " 'natural',\n",
       " 'products',\n",
       " 'research',\n",
       " 'assistant',\n",
       " 'computer',\n",
       " 'skills-',\n",
       " 'good',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'it',\n",
       " 'and',\n",
       " 'confident',\n",
       " 'in',\n",
       " 'using',\n",
       " 'all',\n",
       " 'office',\n",
       " 'applications',\n",
       " 'volunteer',\n",
       " 'attendant',\n",
       " 'computer',\n",
       " 'ms',\n",
       " 'office',\n",
       " 'ltex',\n",
       " 'inkscape',\n",
       " 'image',\n",
       " 'software',\n",
       " 'imagej',\n",
       " 'chembiooffice',\n",
       " 'origin',\n",
       " 'and',\n",
       " 'blender',\n",
       " 'basic',\n",
       " 'bolton',\n",
       " 'supervisor',\n",
       " 'duty',\n",
       " 'manager',\n",
       " 'opening',\n",
       " 'and',\n",
       " 'closing',\n",
       " 'procedures',\n",
       " 'basic',\n",
       " 'food',\n",
       " 'hygiene',\n",
       " 'certificate',\n",
       " 'hospitality',\n",
       " 'course',\n",
       " 'national',\n",
       " 'license',\n",
       " 'certificate',\n",
       " 'phd',\n",
       " 'graduate',\n",
       " 'in',\n",
       " 'mathematics',\n",
       " 'looking',\n",
       " 'to',\n",
       " 'obtain',\n",
       " 'position',\n",
       " 'in',\n",
       " 'global',\n",
       " 'company',\n",
       " 'that',\n",
       " 'works',\n",
       " 'on',\n",
       " 'real-worldproblems',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'use',\n",
       " 'my',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'expertise',\n",
       " 'to',\n",
       " 'contribute',\n",
       " 'significantly',\n",
       " 'to',\n",
       " 'its',\n",
       " 'success',\n",
       " 'ameager',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'and',\n",
       " 'excited',\n",
       " 'about',\n",
       " 'continuation',\n",
       " 'of',\n",
       " 'my',\n",
       " 'career',\n",
       " 'in',\n",
       " 'dynamic',\n",
       " 'industry',\n",
       " 'maple',\n",
       " 'microsoft',\n",
       " 'excel',\n",
       " 'scientific',\n",
       " 'calculations',\n",
       " 'for',\n",
       " 'studying',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'value',\n",
       " 'property',\n",
       " 'of',\n",
       " 'working',\n",
       " 'across',\n",
       " 'distinct',\n",
       " 'areas',\n",
       " 'of',\n",
       " 'pure',\n",
       " 'and',\n",
       " 'applied',\n",
       " 'mathematics',\n",
       " 'demonstrated',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'adopt',\n",
       " 'suitable',\n",
       " 'strategies',\n",
       " 'develop',\n",
       " 'new',\n",
       " 'techniques',\n",
       " 'and',\n",
       " 'think',\n",
       " '``',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'box',\n",
       " \"''\",\n",
       " 'use',\n",
       " 'logical',\n",
       " 'arguments',\n",
       " 'collaborating',\n",
       " 'with',\n",
       " 'engineers',\n",
       " 'on',\n",
       " 'the',\n",
       " 'resent',\n",
       " 'project',\n",
       " 'and',\n",
       " 'working',\n",
       " 'as',\n",
       " 'tutor',\n",
       " 'presented',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'evaluate',\n",
       " 'and',\n",
       " 'give',\n",
       " 'feedback',\n",
       " 'on',\n",
       " 'the',\n",
       " 'work',\n",
       " 'tions',\n",
       " 'posters',\n",
       " 'have',\n",
       " 'developed',\n",
       " 'my',\n",
       " 'written',\n",
       " 'editorial',\n",
       " 'and',\n",
       " 'public',\n",
       " 'speaking',\n",
       " 'skills',\n",
       " 'responding',\n",
       " 'appropriately',\n",
       " 'to',\n",
       " 'positive',\n",
       " 'or',\n",
       " 'negative',\n",
       " 'feedback',\n",
       " 'and',\n",
       " 'as',\n",
       " 'member',\n",
       " 'of',\n",
       " 'large',\n",
       " 'international',\n",
       " 'phd',\n",
       " 'programm',\n",
       " 'have',\n",
       " 'developed',\n",
       " 'my',\n",
       " 'social',\n",
       " 'skills',\n",
       " 'active',\n",
       " 'listening',\n",
       " 'and',\n",
       " 'seeing',\n",
       " 'the',\n",
       " 'point',\n",
       " 'building',\n",
       " 'of',\n",
       " 'fruitful',\n",
       " 'collaboration',\n",
       " 'with',\n",
       " 'colleagues',\n",
       " 'london',\n",
       " 'teaching',\n",
       " 'associate',\n",
       " 'manchester',\n",
       " 'server',\n",
       " 'developer',\n",
       " 'key',\n",
       " 'skills',\n",
       " 'microsoft',\n",
       " 'sql',\n",
       " 'server',\n",
       " 'and',\n",
       " 'postgresql',\n",
       " 'ticket',\n",
       " 'management',\n",
       " 'key',\n",
       " 'skills',\n",
       " 'microsoft',\n",
       " '.net',\n",
       " 'web',\n",
       " 'based',\n",
       " 'asp',\n",
       " '.net',\n",
       " 'and',\n",
       " 'mvc',\n",
       " 'writing',\n",
       " 'and',\n",
       " 'consuming',\n",
       " 'restful',\n",
       " 'apis',\n",
       " 'angular',\n",
       " 'jquery',\n",
       " 'javascript',\n",
       " 'css',\n",
       " 'microsoft',\n",
       " 'sql',\n",
       " 'server',\n",
       " 'and',\n",
       " 'postgresql',\n",
       " 'nunit',\n",
       " 'selenium',\n",
       " 'automated',\n",
       " 'testing',\n",
       " 'perforce',\n",
       " 'git',\n",
       " 'team',\n",
       " 'foundation',\n",
       " 'source',\n",
       " 'control',\n",
       " 'agile',\n",
       " 'scrum',\n",
       " 'development',\n",
       " 'methodology',\n",
       " 'ticket',\n",
       " 'management',\n",
       " 'go',\n",
       " 'live',\n",
       " 'support',\n",
       " 'during',\n",
       " 'phd',\n",
       " 'java',\n",
       " 'as',\n",
       " 'undergrad',\n",
       " 'assistant',\n",
       " 'manager',\n",
       " 'specialist',\n",
       " 'in',\n",
       " 'in-depth',\n",
       " 'inland',\n",
       " 'revenue',\n",
       " 'investigations',\n",
       " 'and',\n",
       " 'all',\n",
       " 'aspects',\n",
       " 'of',\n",
       " 'and',\n",
       " 'the',\n",
       " 'subsequent',\n",
       " 'completion',\n",
       " 'of',\n",
       " 'self-assessment',\n",
       " 'returns',\n",
       " 'general',\n",
       " 'windows',\n",
       " 'applications',\n",
       " 'psychologist',\n",
       " 'graduate',\n",
       " 'engineer',\n",
       " 'private',\n",
       " 'tutor',\n",
       " 'part',\n",
       " 'time',\n",
       " 'can',\n",
       " 'apply',\n",
       " 'mathematical',\n",
       " 'models',\n",
       " 'to',\n",
       " 'characterise',\n",
       " 'data',\n",
       " 'and',\n",
       " 'establish',\n",
       " 'trends',\n",
       " 'effective',\n",
       " 'and',\n",
       " 'confident',\n",
       " 'communicator',\n",
       " 'articulate',\n",
       " 'with',\n",
       " 'extensive',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'scientific',\n",
       " 'writing',\n",
       " 'proof-reading',\n",
       " ...]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalize_data(**kwargs):\n",
    "    tokenizer = kwargs['tokenizer']\n",
    "    normalizer = kwargs['token_format']\n",
    "    spelling = kwargs['spell_correct']\n",
    "    \n",
    "#     data = pd.DataFrame(['asc','asda','asdasdasd'], columns=['value_char'])\n",
    "    \n",
    "    # singularize tokens\n",
    "#     data = data[prefix].map(lambda l: map(lambda w: w.singularize(), l))\n",
    "\n",
    "    # Spell correct flag\n",
    "    # REALLY SHOULD NEVER BE USED\n",
    "#     if spelling:\n",
    "#         print(\"Spell Correction Invoked.....\")\n",
    "#         data[prefix] = data[prefix].map(lambda l: map(lambda wl: map(lambda w: w.correct(), wl), l))\n",
    "#         print(data[prefix].map(lambda l: map(lambda w: type(w), l)))\n",
    "\n",
    "    # filter out 'bad' words, normalize good ones\n",
    "    # w if w not in self.stopWords else wl.remove(w)\n",
    "    aa = cleanestes.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w in stopWords else w, wl), l))\n",
    "    aa = aa.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'s' else w, wl), l))\n",
    "    aa = aa.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'d' else w, wl), l))\n",
    "\n",
    "    # remove tokens with length 1\n",
    "#     ree = re.compile(r'(\\'\\w)')\n",
    "#     rlen = len(data)\n",
    "#     tmp = data[prefix].copy()\n",
    "#     for index in range(0,rlen):\n",
    "#         wl_coll = list()\n",
    "#         for lst in tmp[index]:\n",
    "#             wl = list()\n",
    "#             for word in lst:\n",
    "#                 if not isinstance(word, types.NoneType):\n",
    "#                     if re.match(ree, word):\n",
    "#                         ree.sub('', word)\n",
    "#                     if len(word.strip().strip('.').strip(',')) > 1:\n",
    "#                         wl.append((word))\n",
    "#             wl_coll.append(WordList(wl))\n",
    "#         data[index] = wl_coll\n",
    "#     del tmp\n",
    "\n",
    "    # remove via regexp c'c pattern\n",
    "\n",
    "    # Stemming or lemmatization of tokens    \n",
    "    if normalizer == 'stem':\n",
    "        aa = aa.map(lambda l: map(lambda wl: map(lambda w: stemmer.stem(w) if w in wl and not isinstance(w, types.NoneType) else wl.remove(w), wl), l))\n",
    "#     elif normalizer == 'lemma':\n",
    "#         data[prefix] = data[prefix].map(lambda l: map(lambda wl: map(lambda w: w.lemmatize(), wl), l))\n",
    "#     elif normalizer == 'None':\n",
    "#         pass\n",
    "\n",
    "    aa = aa.map(lambda l: map(lambda wl: map(Word, wl), l))\n",
    "#     data[prefix] = data[prefix].map(lambda l: map(WordList, l))\n",
    "    \n",
    "    return aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize_data(**tokenizer_prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
