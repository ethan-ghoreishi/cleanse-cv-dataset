{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# import types\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.tokenize as nt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from textblob import blob, Blobber, TextBlob, Sentence, Word, WordList, tokenizers, sentiments, taggers, parsers, classifiers\n",
    "#from textblob_aptagger import PerceptronTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = psycopg2.connect(dbname=\"skillsdb\",host=\"dw-instance.cbrlhmbtfrqg.eu-west-2.redshift.amazonaws.com\"\n",
    "                ,port=\"5439\",user=\"masteruser\", password=\"Ehgh1363\")\n",
    "curs = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_sql_query('''select distinct cv.user_id, cv_section_attribute.name,\n",
    "cv.value_char, cv.value_timestamp from cv_section_attribute \n",
    "left join cv on cv_section_attribute.id=cv.cv_section_attribute_id''',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data['value_char'] = data['value_char'].map(lambda x: x.strip() if pd.notnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>value_char</th>\n",
       "      <th>value_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.040579e+11</td>\n",
       "      <td>locale</td>\n",
       "      <td>Mitcham</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.079980e+11</td>\n",
       "      <td>name</td>\n",
       "      <td>Guest Lecturer</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.079980e+11</td>\n",
       "      <td>locale</td>\n",
       "      <td>Crewe</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.928147e+11</td>\n",
       "      <td>name</td>\n",
       "      <td>Pencari Kerja</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.725346e+11</td>\n",
       "      <td>summary</td>\n",
       "      <td>An ambitious and hardworking individual who is...</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id     name                                         value_char  \\\n",
       "0  2.040579e+11   locale                                            Mitcham   \n",
       "1  2.079980e+11     name                                     Guest Lecturer   \n",
       "2  2.079980e+11   locale                                              Crewe   \n",
       "3  2.928147e+11     name                                      Pencari Kerja   \n",
       "4  2.725346e+11  summary  An ambitious and hardworking individual who is...   \n",
       "\n",
       "  value_timestamp  \n",
       "0             NaT  \n",
       "1             NaT  \n",
       "2             NaT  \n",
       "3             NaT  \n",
       "4             NaT  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>value_char</th>\n",
       "      <th>value_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.040579e+11</td>\n",
       "      <td>locale</td>\n",
       "      <td>Mitcham</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.079980e+11</td>\n",
       "      <td>name</td>\n",
       "      <td>Guest Lecturer</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.079980e+11</td>\n",
       "      <td>locale</td>\n",
       "      <td>Crewe</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.928147e+11</td>\n",
       "      <td>name</td>\n",
       "      <td>Pencari Kerja</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.725346e+11</td>\n",
       "      <td>summary</td>\n",
       "      <td>An ambitious and hardworking individual who is...</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id     name                                         value_char  \\\n",
       "0  2.040579e+11   locale                                            Mitcham   \n",
       "1  2.079980e+11     name                                     Guest Lecturer   \n",
       "2  2.079980e+11   locale                                              Crewe   \n",
       "3  2.928147e+11     name                                      Pencari Kerja   \n",
       "4  2.725346e+11  summary  An ambitious and hardworking individual who is...   \n",
       "\n",
       "  value_timestamp  \n",
       "0             NaT  \n",
       "1             NaT  \n",
       "2             NaT  \n",
       "3             NaT  \n",
       "4             NaT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid = data[data['name'].isin(['locale','name','summary','headline',\n",
    "                                     'degree','school','admit_year','grad_year',\n",
    "                                     'company',  'title',  'work_location',  \n",
    "                                     'start_date','end_date', 'description',\n",
    "                                     'award',\n",
    "                                     'publication', \n",
    "                                     'additional_info', \n",
    "                                     'skill'])]\n",
    "data_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(prefix=None):\n",
    "    '''\n",
    "    Cleans text data by:\n",
    "    1.  force lowercase\n",
    "    2.  remove non-ascii chars\n",
    "    3.  standardize whitespace\n",
    "    4.  remove digits\n",
    "    5.  remove control characters\n",
    "    6.  remove URL patterns\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        df = data_valid[prefix].dropna().map(lambda x: \"\".join(i for i in x.strip().lower() if ord(i)<128))\n",
    "    except UnicodeDecodeError:\n",
    "        print(UnicodeDecodeError)\n",
    "        df = data_valid[prefix].dropna().map(lambda x: x.strip().lower())\n",
    "\n",
    "        #     except Exception:\n",
    "#         print(Exception)\n",
    "#     finally:\n",
    "#         data[prefix]= data[prefix].map(lambda x: x.lower())\n",
    "\n",
    "    url_pattern = \"((http|ftp|https):\\/\\/)?[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;/~\\+#])?\"\n",
    "\n",
    "    re_URL = re.compile(url_pattern)\n",
    "#     re_TAG = re.compile(\"(<[phl]>)\", re.IGNORECASE)\n",
    "    re_WS = re.compile(\"/[^\\S\\n]/\")\n",
    "#     re_DIGIT = re.compile(\"\\d\")\n",
    "    re_CTRL = re.compile(\"[\\x00-\\x11\\x03-\\x1F]+\")\n",
    "    re_HI = re.compile(\"[\\x80-\\xFF]+\")\n",
    "    re_NWC = re.compile(\"[!;<>?{}\\/~`#=@#$%^&*()_+]\")\n",
    "    \n",
    "    df = df.map(lambda x: re_HI.sub(' ', x))\n",
    "    df = df.map(lambda x: re_CTRL.sub(' ', x))\n",
    "    df = df.map(lambda x: re_URL.sub(' ', x))\n",
    "#     data[prefix] = data[prefix].map(lambda x: re_DIGIT.sub(' ', x))\n",
    "    df = df.map(lambda x: re_WS.sub(' ', x))        \n",
    "    df = df.map(lambda x: re_NWC.sub(' ', x))\n",
    "    df = df.map(lambda x: x.strip())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              mitcham\n",
       "1                                       guest lecturer\n",
       "2                                                crewe\n",
       "3                                        pencari kerja\n",
       "4    an ambitious and hardworking individual who is...\n",
       "Name: value_char, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('value_char').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mitcham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guest lecturer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crewe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pencari kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an ambitious and hardworking individual who is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_char\n",
       "0                                            mitcham\n",
       "1                                     guest lecturer\n",
       "2                                              crewe\n",
       "3                                      pencari kerja\n",
       "4  an ambitious and hardworking individual who is..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.DataFrame()\n",
    "data_clean['value_char'] = clean_text('value_char')\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_valid = data_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[lecturer in project management]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[a creative and well-rounded graduate with a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[part time lecturing and lab demonstrator]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[leicestershire, uk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[natural products research assistant]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_char\n",
       "0                   [lecturer in project management]\n",
       "1  [a creative and well-rounded graduate with a f...\n",
       "2         [part time lecturing and lab demonstrator]\n",
       "3                               [leicestershire, uk]\n",
       "5              [natural products research assistant]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenization\n",
    "\n",
    "# initialize the tokenizer\n",
    "\n",
    "tokenizer = nltk.tokenize.PunktSentenceTokenizer()\n",
    "\n",
    "# tokenize data\n",
    "\n",
    "data_clean['value_char'] = data_clean['value_char'].map(lambda x: tokenizer.tokenize(x.strip()))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opening and closing procedures'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.value_char[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word_tokenizer = nltk.tokenize.word_tokenize()\n",
    "# data_clean['value_char'] = data_clean['value_char'].map(lambda x: nltk.tokenize.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Stemming\n",
    "\n",
    "# initialize the stemmer\n",
    "\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "# data_clean['value_char'].map(lambda x: (i for i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lemmatize = nltk.WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_headlines = data[data['name'] == 'headline'].reset_index()[['user_id','value_char']]\n",
    "cv_degrees = data[data['name'] == 'degree'].reset_index()[['user_id','value_char']]\n",
    "cv_schools = data[data['name'] == 'school'].reset_index()[['user_id','value_char']]\n",
    "cv_locales = data[data['name'] == 'locale'].reset_index()[['user_id','value_char']]\n",
    "cv_summaries = data[data['name'] == 'summary'].reset_index()[['user_id','value_char']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "tokenizer_prefs = {\n",
    "    'tokenizer' : nltk.tokenize.PunktSentenceTokenizer(),\n",
    "    'token_format' : 'stem',\n",
    "    'spell_correct' : False,\n",
    "    'np_extract': None,\n",
    "    'pos_tagger': None,\n",
    "    'analyzer': None,\n",
    "    'classifier': None, \n",
    "    'clean_html': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_blob(prefix, **kwargs):\n",
    "    \n",
    "    tokenizer = kwargs['tokenizer']\n",
    "    pos_tagger = kwargs['pos_tagger']\n",
    "    analyzer = kwargs['analyzer']\n",
    "    classifier = kwargs['classifier']\n",
    "    np_extract = kwargs['np_extract']\n",
    "    \n",
    "    blob = data_clean[prefix].map(lambda l: TextBlob(l,\n",
    "                                          tokenizer=tokenizer,\n",
    "                                           np_extractor=np_extract,\n",
    "                                           pos_tagger=pos_tagger,\n",
    "                                           analyzer=analyzer,\n",
    "                                           classifier=classifier))\n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"mitcham\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_blobs = pd.DataFrame()\n",
    "data_blobs['value_char'] = create_blob('value_char', **tokenizer_prefs)\n",
    "data_blobs.value_char[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_sentences(prefix, **kwargs):\n",
    "    tokenizer = kwargs['tokenizer']\n",
    "    normalizer = kwargs['token_format']\n",
    "\n",
    "    # tokenize the document into sentences from blob object\n",
    "    sentences = data_blobs[prefix].map(lambda s: s.sentences)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"mitcham\")]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sentence_tokenized = pd.DataFrame()\n",
    "data_sentence_tokenized['value_char'] = tokenize_sentences('value_char', **tokenizer_prefs)\n",
    "data_sentence_tokenized.value_char[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_words(prefix, normalize = 'stem', **kwargs):\n",
    "    tokenizer = kwargs['tokenizer']\n",
    "    normalizer = kwargs['token_format']\n",
    "\n",
    "    # tokenize each sentence into words\n",
    "    # trim token whitespaces\n",
    "    # eliminate tokens of character length 1\n",
    "    #words = self.data[prefix].map(lambda w: w.strip().tokens if len(w)>1 else None)\n",
    "\n",
    "    words = data_sentence_tokenized[prefix].map(lambda l: map(lambda w: w.strip().tokens if len(w)>1 else None, l))\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_word_tokenized = pd.DataFrame()\n",
    "data_word_tokenized = tokenize_words('value_char', **tokenizer_prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeNoneTypes(lst):\n",
    "    return [i for i in lst if type(i) is not type(None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(data_word_tokenized, **kwargs):\n",
    "    tokenizer = kwargs['tokenizer']\n",
    "    normalizer = kwargs['token_format']\n",
    "    spelling = kwargs['spell_correct']\n",
    "    \n",
    "    data = self.data[prefix].map(lambda l: map(lambda wl: self.removeNoneTypes(wl), l))\n",
    "    data_normalized = data_word_tokenized.map(lambda l: map(lambda w: w.singularize(), l))\n",
    "    \n",
    "    # filter out 'bad' words, normalize good ones\n",
    "    # w if w not in self.stopWords else wl.remove(w)\n",
    "    data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w in stopWords else w, wl), l))\n",
    "    data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'s' else w, wl), l))\n",
    "    data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'d' else w, wl), l))\n",
    " \n",
    "     # remove tokens with length 1\n",
    "#     ree = re.compile(r'(\\'\\w)')\n",
    "#     rlen = len(data_normalized)\n",
    "#     tmp = data_normalized.copy()\n",
    "# #     tmp.reset_index(drop=True)\n",
    "#     for indx in tmp.index:\n",
    "#         wl_coll = list()\n",
    "#         for lst in tmp[indx]:\n",
    "#             wl = list()\n",
    "#             for word in lst:\n",
    "#                     for i in word:\n",
    "#                             if re.match(ree, i):\n",
    "#                                 ree.sub('', i)\n",
    "#                             if len(i.strip().strip('.').strip(',')) > 1:\n",
    "#                                 wl.append((i))\n",
    "#             wl_coll.append(WordList(wl))\n",
    "#         data_normalized[indx] = wl_coll\n",
    "#     del tmp\n",
    "\n",
    "    # stemming\n",
    "    data_normalized = data_normalized.map(lambda l: map(lambda wl: map(lambda w: nltk.stemmer.stem(w) if w in wl and not isinstance(w, types.NoneType) else wl.remove(w), wl), l))\n",
    "\n",
    "    data_word_tokenized= tokenize_words('value_char', **tokenizer_prefs)\n",
    "    \n",
    "    return data_word_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "tokenizer  =   RegexpTokenizer(pattern=r'\\w+')\n",
    "stemmer    =   nltk.stem.PorterStemmer.NLTK_EXTENSIONS\n",
    "lemmatize  =   nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <map object at 0x7fbaacbec198>\n",
       "1        <map object at 0x7fbaacbec208>\n",
       "2        <map object at 0x7fbaacbec278>\n",
       "3        <map object at 0x7fbaacbec320>\n",
       "4        <map object at 0x7fbaacbec3c8>\n",
       "6        <map object at 0x7fbaacbec470>\n",
       "7        <map object at 0x7fbaacbec518>\n",
       "8        <map object at 0x7fbaacbec5c0>\n",
       "9        <map object at 0x7fbaacbec668>\n",
       "10       <map object at 0x7fbaacbec710>\n",
       "11       <map object at 0x7fbaacbec7b8>\n",
       "12       <map object at 0x7fbaacbec860>\n",
       "13       <map object at 0x7fbaacbec908>\n",
       "14       <map object at 0x7fbaacbec9b0>\n",
       "18       <map object at 0x7fbaacbeca58>\n",
       "19       <map object at 0x7fbaacbecb00>\n",
       "21       <map object at 0x7fbaacbecba8>\n",
       "22       <map object at 0x7fbaacbecc50>\n",
       "23       <map object at 0x7fbaacbeccf8>\n",
       "24       <map object at 0x7fbaacbecda0>\n",
       "25       <map object at 0x7fbaacbece48>\n",
       "29       <map object at 0x7fbaacbecef0>\n",
       "30       <map object at 0x7fbaacbecf98>\n",
       "31       <map object at 0x7fbaacbee080>\n",
       "32       <map object at 0x7fbaacbee128>\n",
       "33       <map object at 0x7fbaacbee1d0>\n",
       "34       <map object at 0x7fbaacbee278>\n",
       "35       <map object at 0x7fbaacbee320>\n",
       "36       <map object at 0x7fbaacbee3c8>\n",
       "37       <map object at 0x7fbaacbee470>\n",
       "                      ...              \n",
       "26744    <map object at 0x7fbaac534b00>\n",
       "26745    <map object at 0x7fbaac534ba8>\n",
       "26746    <map object at 0x7fbaac534c50>\n",
       "26747    <map object at 0x7fbaac534cf8>\n",
       "26748    <map object at 0x7fbaac534da0>\n",
       "26749    <map object at 0x7fbaac534e48>\n",
       "26751    <map object at 0x7fbaac534ef0>\n",
       "26752    <map object at 0x7fbaac534f98>\n",
       "26753    <map object at 0x7fbaac536080>\n",
       "26754    <map object at 0x7fbaac536128>\n",
       "26755    <map object at 0x7fbaac5361d0>\n",
       "26756    <map object at 0x7fbaac536278>\n",
       "26757    <map object at 0x7fbaac536320>\n",
       "26758    <map object at 0x7fbaac5363c8>\n",
       "26759    <map object at 0x7fbaac536470>\n",
       "26760    <map object at 0x7fbaac536518>\n",
       "26761    <map object at 0x7fbaac5365c0>\n",
       "26762    <map object at 0x7fbaac536668>\n",
       "26763    <map object at 0x7fbaac536710>\n",
       "26764    <map object at 0x7fbaac5367b8>\n",
       "26765    <map object at 0x7fbaac536860>\n",
       "26767    <map object at 0x7fbaac536908>\n",
       "26768    <map object at 0x7fbaac5369b0>\n",
       "26769    <map object at 0x7fbaac536a58>\n",
       "26770    <map object at 0x7fbaac536b00>\n",
       "26771    <map object at 0x7fbaac536ba8>\n",
       "26772    <map object at 0x7fbaac536c50>\n",
       "26773    <map object at 0x7fbaac536cf8>\n",
       "26774    <map object at 0x7fbaac536da0>\n",
       "26775    <map object at 0x7fbaac536e48>\n",
       "Name: value_char, Length: 22845, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(data_word_tokenized,**tokenizer_prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ree = re.compile(r'(\\'\\w)')\n",
    "wl = list()\n",
    "\n",
    "for i in normalize(data_word_tokenized,**tokenizer_prefs):\n",
    "    for j in i:\n",
    "        if not isinstance(j, type(None)):\n",
    "            for k in j:\n",
    "                if not isinstance(k, type(None)):\n",
    "                    if re.match(ree, k):\n",
    "                        ree.sub('', k)\n",
    "                    if len(k.strip().strip('.').strip(',')) > 1:\n",
    "                        wl.append((k))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mitcham',\n",
       " 'guest',\n",
       " 'lecturer',\n",
       " 'crewe',\n",
       " 'pencari',\n",
       " 'kerja',\n",
       " 'an',\n",
       " 'ambitious',\n",
       " 'and',\n",
       " 'hardworking',\n",
       " 'individual',\n",
       " 'who',\n",
       " 'is',\n",
       " 'motivated',\n",
       " 'by',\n",
       " 'challenge',\n",
       " 'and',\n",
       " 'is',\n",
       " 'passionate',\n",
       " 'to',\n",
       " 'be',\n",
       " 'successful',\n",
       " 'inventor',\n",
       " 'on',\n",
       " 'four',\n",
       " 'patents',\n",
       " 'excellent',\n",
       " 'communicator',\n",
       " 'strong',\n",
       " 'planning',\n",
       " 'organisational',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'skills',\n",
       " 'with',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'successfully',\n",
       " 'analyse',\n",
       " 'and',\n",
       " 'assimilate',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'complex',\n",
       " 'and',\n",
       " 'disparate',\n",
       " 'information',\n",
       " 'good',\n",
       " 'time',\n",
       " 'management',\n",
       " 'enjoys',\n",
       " 'working',\n",
       " 'under',\n",
       " 'pressure',\n",
       " 'and',\n",
       " 'to',\n",
       " 'deadlines',\n",
       " 'either',\n",
       " 'individually',\n",
       " 'or',\n",
       " 'as',\n",
       " 'part',\n",
       " 'of',\n",
       " 'team',\n",
       " 'conversational',\n",
       " 'german',\n",
       " 'part',\n",
       " 'time',\n",
       " 'lecturing',\n",
       " 'and',\n",
       " 'lab',\n",
       " 'demonstrator',\n",
       " 'project',\n",
       " 'evaluation',\n",
       " 'and',\n",
       " 'responsible',\n",
       " 'innovation',\n",
       " 'intern',\n",
       " 'computer',\n",
       " 'skills-',\n",
       " 'good',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'it',\n",
       " 'and',\n",
       " 'confident',\n",
       " 'in',\n",
       " 'using',\n",
       " 'all',\n",
       " 'office',\n",
       " 'full',\n",
       " 'uk',\n",
       " 'driving',\n",
       " 'license',\n",
       " 'dewsbury',\n",
       " 'research',\n",
       " 'intern',\n",
       " 'micro',\n",
       " 'bio',\n",
       " 'nanofluidics',\n",
       " 'unit',\n",
       " 'attendant',\n",
       " 'lab',\n",
       " 'skills',\n",
       " 'spectroscopy',\n",
       " 'infra-red',\n",
       " 'spectroscopy',\n",
       " 'surface-tensiometry',\n",
       " 'conductivity',\n",
       " 'electron',\n",
       " 'microscopy',\n",
       " 'polymerisation',\n",
       " 'techniques',\n",
       " 'inc.',\n",
       " 'emulsion',\n",
       " 'dispersion',\n",
       " 'polymerisation',\n",
       " 'rheology',\n",
       " 'micro-piv',\n",
       " 'microfluidics',\n",
       " 'skillslight-scattering',\n",
       " 'techniques',\n",
       " 'inkjet',\n",
       " 'printing',\n",
       " 'nmr',\n",
       " 'size-exclusion',\n",
       " 'chromatograhy',\n",
       " 'uv-visible',\n",
       " 'spectroscopy',\n",
       " 'fluorescencelab',\n",
       " 'skills',\n",
       " 'spectroscopy',\n",
       " 'infra-red',\n",
       " 'spectroscopy',\n",
       " 'surface-tensiometry',\n",
       " 'conductivity',\n",
       " 'electron',\n",
       " 'microscopy',\n",
       " 'polymerisation',\n",
       " 'techniques',\n",
       " 'inc.',\n",
       " 'emulsion',\n",
       " 'dispersion',\n",
       " 'polymerisation',\n",
       " 'rheology',\n",
       " 'micro-piv',\n",
       " 'microfluidicscomputer',\n",
       " 'ms',\n",
       " 'office',\n",
       " 'ltex',\n",
       " 'inkscape',\n",
       " 'image',\n",
       " 'software',\n",
       " 'imagej',\n",
       " 'chembiooffice',\n",
       " 'origin',\n",
       " 'and',\n",
       " 'blender',\n",
       " 'basic',\n",
       " 'team',\n",
       " 'leader',\n",
       " 'night',\n",
       " 'manager',\n",
       " 'london',\n",
       " 'excellent',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'skills',\n",
       " 'personnel',\n",
       " 'development',\n",
       " 'merchandising',\n",
       " 'staff',\n",
       " 'training',\n",
       " 'and',\n",
       " 'development',\n",
       " 'liverpool',\n",
       " 'postdoctoral',\n",
       " 'research',\n",
       " 'assistant',\n",
       " 'it',\n",
       " 'proficiency',\n",
       " 'and',\n",
       " 'programming',\n",
       " 'skills',\n",
       " 'matlab',\n",
       " 'creating',\n",
       " 'simulations',\n",
       " 'of',\n",
       " 'wave',\n",
       " 'propagation',\n",
       " 'on',\n",
       " 'flexural',\n",
       " 'systems',\n",
       " '2015',\n",
       " 'for',\n",
       " 'different',\n",
       " 'sequences',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'and',\n",
       " 'finite-state',\n",
       " 'automaton',\n",
       " 'simulators',\n",
       " 'numerical',\n",
       " 'solution',\n",
       " 'of',\n",
       " 'sql',\n",
       " 'started',\n",
       " 'to',\n",
       " 'study',\n",
       " 'coursera',\n",
       " '2016-',\n",
       " 'analytical',\n",
       " 'and',\n",
       " 'critical',\n",
       " 'thinking',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'synthesize',\n",
       " 'large',\n",
       " 'quantities',\n",
       " 'of',\n",
       " 'complex',\n",
       " 'data',\n",
       " 'range',\n",
       " 'of',\n",
       " 'activities',\n",
       " 'including',\n",
       " 'teaching',\n",
       " 'preparing',\n",
       " 'phd',\n",
       " 'thesis',\n",
       " 'research',\n",
       " 'papers',\n",
       " 'conference',\n",
       " 'presenta-',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'contribute',\n",
       " 'expertise',\n",
       " 'and',\n",
       " 'follow',\n",
       " 'leadership',\n",
       " 'directives',\n",
       " 'at',\n",
       " 'appropriate',\n",
       " 'times',\n",
       " 'marple',\n",
       " 'cheshire',\n",
       " 'uk',\n",
       " 'chemical',\n",
       " 'engineer',\n",
       " 'with',\n",
       " 'significant',\n",
       " 'experience',\n",
       " 'of',\n",
       " 'working',\n",
       " 'as',\n",
       " 'part',\n",
       " 'of',\n",
       " 'team',\n",
       " 'and',\n",
       " 'individually',\n",
       " 'in',\n",
       " 'timeline',\n",
       " 'driven',\n",
       " 'highly',\n",
       " 'pressurised',\n",
       " 'industrial',\n",
       " 'and',\n",
       " 'academic',\n",
       " 'environments',\n",
       " 'this',\n",
       " 'experience',\n",
       " 'has',\n",
       " 'been',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'large',\n",
       " 'range',\n",
       " 'of',\n",
       " 'projects',\n",
       " 'in',\n",
       " 'chemical',\n",
       " 'engineering',\n",
       " 'science',\n",
       " 'and',\n",
       " 'biotechnology',\n",
       " 'following',\n",
       " 'several',\n",
       " 'bachelor',\n",
       " 'degrees',\n",
       " 'and',\n",
       " 'phd',\n",
       " 'in',\n",
       " 'chemical',\n",
       " 'engineering',\n",
       " 'this',\n",
       " 'has',\n",
       " 'manifested',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'two',\n",
       " 'patent',\n",
       " 'applications',\n",
       " 'of',\n",
       " 'which',\n",
       " 'am',\n",
       " 'co-inventor',\n",
       " 'this',\n",
       " 'industrial',\n",
       " 'experience',\n",
       " 'combined',\n",
       " 'with',\n",
       " 'postgraduate',\n",
       " 'training',\n",
       " 'has',\n",
       " 'been',\n",
       " 'in',\n",
       " 'multi-disciplinary',\n",
       " 'environments',\n",
       " 'enabling',\n",
       " 'effective',\n",
       " 'communication',\n",
       " 'with',\n",
       " 'people',\n",
       " 'from',\n",
       " 'very',\n",
       " 'different',\n",
       " 'technical',\n",
       " 'and',\n",
       " 'non-technical',\n",
       " 'backgrounds',\n",
       " 'also',\n",
       " 'currently',\n",
       " 'in',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'applying',\n",
       " 'for',\n",
       " 'chartership',\n",
       " 'london',\n",
       " 'registered',\n",
       " 'manager',\n",
       " 'london',\n",
       " 'demonstrator',\n",
       " 'chess',\n",
       " 'teacher',\n",
       " 'london',\n",
       " 'persian',\n",
       " 'native',\n",
       " 'general',\n",
       " 'operation',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'benfleet',\n",
       " 'matching',\n",
       " 'programming',\n",
       " 'matlab',\n",
       " 'scilab',\n",
       " 'shell',\n",
       " 'script',\n",
       " 'proficient',\n",
       " 'in',\n",
       " 'the',\n",
       " 'development',\n",
       " 'in',\n",
       " 'windows',\n",
       " 'and',\n",
       " 'linux',\n",
       " 'eigen',\n",
       " 'boost',\n",
       " 'opengl',\n",
       " 'etc',\n",
       " 'principal',\n",
       " 'scientist',\n",
       " 'sheffield',\n",
       " 'laboratory',\n",
       " 'demonstrator',\n",
       " 'legal',\n",
       " 'researcher',\n",
       " 'freelance',\n",
       " 'writer',\n",
       " 'all',\n",
       " 'areas',\n",
       " 'trainee',\n",
       " 'paralegal',\n",
       " 'have',\n",
       " 'excellent',\n",
       " 'skills',\n",
       " 'gained',\n",
       " 'through',\n",
       " 'regularly',\n",
       " 'using',\n",
       " 'window',\n",
       " 'based',\n",
       " 'applications',\n",
       " 'such',\n",
       " 'as',\n",
       " 'microsoft',\n",
       " 'word',\n",
       " 'microsoft',\n",
       " 'excel',\n",
       " 'microsoft',\n",
       " 'powerpoint',\n",
       " 'computer',\n",
       " 'and',\n",
       " 'language',\n",
       " 'skills',\n",
       " 'have',\n",
       " 'excellent',\n",
       " 'skills',\n",
       " 'gained',\n",
       " 'through',\n",
       " 'regularly',\n",
       " 'using',\n",
       " 'window',\n",
       " 'based',\n",
       " 'applications',\n",
       " 'such',\n",
       " 'as',\n",
       " 'microsoft',\n",
       " 'word',\n",
       " 'microsoft',\n",
       " 'excel',\n",
       " 'microsoft',\n",
       " 'powerpoint',\n",
       " 'have',\n",
       " 'obtained',\n",
       " 'certificate',\n",
       " 'in',\n",
       " 'key',\n",
       " 'skills',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'at',\n",
       " 'level',\n",
       " 'can',\n",
       " 'read',\n",
       " 'speak',\n",
       " 'and',\n",
       " 'write',\n",
       " 'in',\n",
       " 'french',\n",
       " 'at',\n",
       " 'an',\n",
       " 'advanced',\n",
       " 'level',\n",
       " 'can',\n",
       " 'speak',\n",
       " 'my',\n",
       " 'mother',\n",
       " 'tongue',\n",
       " 'language',\n",
       " 'punjabi',\n",
       " 'fluently',\n",
       " 'currently',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'activities',\n",
       " 'am',\n",
       " 'and',\n",
       " 'enthusiastic',\n",
       " 'runner',\n",
       " 'am',\n",
       " 'greatly',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'mountain',\n",
       " 'climbing',\n",
       " 'as',\n",
       " 'recenlty',\n",
       " 'discovered',\n",
       " 'when',\n",
       " 'climbing',\n",
       " 'mount',\n",
       " 'sinai',\n",
       " 'in',\n",
       " 'north',\n",
       " 'africa',\n",
       " 'like',\n",
       " 'travelling',\n",
       " 'and',\n",
       " 'have',\n",
       " 'recently',\n",
       " 'been',\n",
       " 'backpacking',\n",
       " 'in',\n",
       " 'the',\n",
       " 'artic',\n",
       " 'circle',\n",
       " 'languages',\n",
       " 'and',\n",
       " 'different',\n",
       " 'cultures',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'greatly',\n",
       " 'am',\n",
       " 'first',\n",
       " 'aider',\n",
       " 'hold',\n",
       " 'full',\n",
       " 'clean',\n",
       " 'driving',\n",
       " 'like',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'up',\n",
       " 'to',\n",
       " 'date',\n",
       " 'with',\n",
       " 'current',\n",
       " 'affairs',\n",
       " 'and',\n",
       " 'legal',\n",
       " 'issues',\n",
       " 'birmingham',\n",
       " 'consultant',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'developer',\n",
       " 'credit',\n",
       " 'risk',\n",
       " 'analyst',\n",
       " 'lavastorm',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'with',\n",
       " 'business',\n",
       " 'intelligence',\n",
       " 'tools',\n",
       " 'such',\n",
       " 'as',\n",
       " 'qlikview',\n",
       " 'tableau',\n",
       " 'and',\n",
       " 'omniscope',\n",
       " 'cheltenham',\n",
       " 'adel',\n",
       " 'ia',\n",
       " 'marketing',\n",
       " 'manager',\n",
       " 'emea',\n",
       " 'norwich',\n",
       " 'associate',\n",
       " 'producer',\n",
       " 'production',\n",
       " 'manager',\n",
       " 'art',\n",
       " 'coordinator',\n",
       " 'associate',\n",
       " 'tutor',\n",
       " 'exam',\n",
       " 'invigilation',\n",
       " 'case',\n",
       " 'manager',\n",
       " 'job',\n",
       " 'seeker',\n",
       " 'member',\n",
       " 'of',\n",
       " 'school',\n",
       " 'executive',\n",
       " 'nottingham',\n",
       " 'talent',\n",
       " 'match',\n",
       " 'sheffield',\n",
       " 'city',\n",
       " 'region',\n",
       " 'programme',\n",
       " 'administrator',\n",
       " 'american',\n",
       " 'fork',\n",
       " 'ut',\n",
       " 'independent',\n",
       " 'consultant',\n",
       " 'global',\n",
       " 'health',\n",
       " 'sector',\n",
       " 'capacity',\n",
       " 'builder',\n",
       " 'lecturer',\n",
       " 'in',\n",
       " 'project',\n",
       " 'management',\n",
       " 'creative',\n",
       " 'and',\n",
       " 'well-rounded',\n",
       " 'graduate',\n",
       " 'with',\n",
       " 'first',\n",
       " 'class',\n",
       " 'honours',\n",
       " 'degree',\n",
       " 'in',\n",
       " 'english',\n",
       " 'and',\n",
       " 'creativewriting',\n",
       " 'and',\n",
       " 'masters',\n",
       " 'in',\n",
       " 'medical',\n",
       " 'humanities',\n",
       " 'currently',\n",
       " 'completing',\n",
       " 'phd',\n",
       " 'significant',\n",
       " 'experienceof',\n",
       " 'managing',\n",
       " 'and',\n",
       " 'motivating',\n",
       " 'large',\n",
       " 'teams',\n",
       " 'in',\n",
       " 'the',\n",
       " 'volunteering',\n",
       " 'and',\n",
       " 'charitable',\n",
       " 'sectors',\n",
       " 'exceptionalknowledge',\n",
       " 'of',\n",
       " 'the',\n",
       " 'social',\n",
       " 'cultural',\n",
       " 'legislative',\n",
       " 'and',\n",
       " 'personal',\n",
       " 'issues',\n",
       " 'those',\n",
       " 'with',\n",
       " 'disabilities',\n",
       " 'face',\n",
       " 'attentive',\n",
       " 'todetail',\n",
       " 'with',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'freelance',\n",
       " 'editing',\n",
       " 'and',\n",
       " 'copywriting',\n",
       " 'confident',\n",
       " 'and',\n",
       " 'enthusiastic',\n",
       " 'with',\n",
       " 'excellentcommunication',\n",
       " 'skills',\n",
       " 'natural',\n",
       " 'leader',\n",
       " 'and',\n",
       " 'hands',\n",
       " 'on',\n",
       " 'team',\n",
       " 'worker',\n",
       " 'who',\n",
       " 'is',\n",
       " 'effective',\n",
       " 'at',\n",
       " 'time',\n",
       " 'managementand',\n",
       " 'presentations',\n",
       " 'to',\n",
       " 'groups',\n",
       " 'thrives',\n",
       " 'on',\n",
       " 'new',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'goals',\n",
       " 'part',\n",
       " 'time',\n",
       " 'lecturing',\n",
       " 'and',\n",
       " 'lab',\n",
       " 'demonstrator',\n",
       " 'leicestershire',\n",
       " 'uk',\n",
       " 'natural',\n",
       " 'products',\n",
       " 'research',\n",
       " 'assistant',\n",
       " 'computer',\n",
       " 'skills-',\n",
       " 'good',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'it',\n",
       " 'and',\n",
       " 'confident',\n",
       " 'in',\n",
       " 'using',\n",
       " 'all',\n",
       " 'office',\n",
       " 'applications',\n",
       " 'volunteer',\n",
       " 'attendant',\n",
       " 'computer',\n",
       " 'ms',\n",
       " 'office',\n",
       " 'ltex',\n",
       " 'inkscape',\n",
       " 'image',\n",
       " 'software',\n",
       " 'imagej',\n",
       " 'chembiooffice',\n",
       " 'origin',\n",
       " 'and',\n",
       " 'blender',\n",
       " 'basic',\n",
       " 'bolton',\n",
       " 'supervisor',\n",
       " 'duty',\n",
       " 'manager',\n",
       " 'opening',\n",
       " 'and',\n",
       " 'closing',\n",
       " 'procedures',\n",
       " 'basic',\n",
       " 'food',\n",
       " 'hygiene',\n",
       " 'certificate',\n",
       " 'hospitality',\n",
       " 'course',\n",
       " 'national',\n",
       " 'license',\n",
       " 'certificate',\n",
       " 'phd',\n",
       " 'graduate',\n",
       " 'in',\n",
       " 'mathematics',\n",
       " 'looking',\n",
       " 'to',\n",
       " 'obtain',\n",
       " 'position',\n",
       " 'in',\n",
       " 'global',\n",
       " 'company',\n",
       " 'that',\n",
       " 'works',\n",
       " 'on',\n",
       " 'real-worldproblems',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'use',\n",
       " 'my',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'expertise',\n",
       " 'to',\n",
       " 'contribute',\n",
       " 'significantly',\n",
       " 'to',\n",
       " 'its',\n",
       " 'success',\n",
       " 'ameager',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'and',\n",
       " 'excited',\n",
       " 'about',\n",
       " 'continuation',\n",
       " 'of',\n",
       " 'my',\n",
       " 'career',\n",
       " 'in',\n",
       " 'dynamic',\n",
       " 'industry',\n",
       " 'maple',\n",
       " 'microsoft',\n",
       " 'excel',\n",
       " 'scientific',\n",
       " 'calculations',\n",
       " 'for',\n",
       " 'studying',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'value',\n",
       " 'property',\n",
       " 'of',\n",
       " 'working',\n",
       " 'across',\n",
       " 'distinct',\n",
       " 'areas',\n",
       " 'of',\n",
       " 'pure',\n",
       " 'and',\n",
       " 'applied',\n",
       " 'mathematics',\n",
       " 'demonstrated',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'adopt',\n",
       " 'suitable',\n",
       " 'strategies',\n",
       " 'develop',\n",
       " 'new',\n",
       " 'techniques',\n",
       " 'and',\n",
       " 'think',\n",
       " '``',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'box',\n",
       " \"''\",\n",
       " 'use',\n",
       " 'logical',\n",
       " 'arguments',\n",
       " 'collaborating',\n",
       " 'with',\n",
       " 'engineers',\n",
       " 'on',\n",
       " 'the',\n",
       " 'resent',\n",
       " 'project',\n",
       " 'and',\n",
       " 'working',\n",
       " 'as',\n",
       " 'tutor',\n",
       " 'presented',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'evaluate',\n",
       " 'and',\n",
       " 'give',\n",
       " 'feedback',\n",
       " 'on',\n",
       " 'the',\n",
       " 'work',\n",
       " 'tions',\n",
       " 'posters',\n",
       " 'have',\n",
       " 'developed',\n",
       " 'my',\n",
       " 'written',\n",
       " 'editorial',\n",
       " 'and',\n",
       " 'public',\n",
       " 'speaking',\n",
       " 'skills',\n",
       " 'responding',\n",
       " 'appropriately',\n",
       " 'to',\n",
       " 'positive',\n",
       " 'or',\n",
       " 'negative',\n",
       " 'feedback',\n",
       " 'and',\n",
       " 'as',\n",
       " 'member',\n",
       " 'of',\n",
       " 'large',\n",
       " 'international',\n",
       " 'phd',\n",
       " 'programm',\n",
       " 'have',\n",
       " 'developed',\n",
       " 'my',\n",
       " 'social',\n",
       " 'skills',\n",
       " 'active',\n",
       " 'listening',\n",
       " 'and',\n",
       " 'seeing',\n",
       " 'the',\n",
       " 'point',\n",
       " 'building',\n",
       " 'of',\n",
       " 'fruitful',\n",
       " 'collaboration',\n",
       " 'with',\n",
       " 'colleagues',\n",
       " 'london',\n",
       " 'teaching',\n",
       " 'associate',\n",
       " 'manchester',\n",
       " 'server',\n",
       " 'developer',\n",
       " 'key',\n",
       " 'skills',\n",
       " 'microsoft',\n",
       " 'sql',\n",
       " 'server',\n",
       " 'and',\n",
       " 'postgresql',\n",
       " 'ticket',\n",
       " 'management',\n",
       " 'key',\n",
       " 'skills',\n",
       " 'microsoft',\n",
       " '.net',\n",
       " 'web',\n",
       " 'based',\n",
       " 'asp',\n",
       " '.net',\n",
       " 'and',\n",
       " 'mvc',\n",
       " 'writing',\n",
       " 'and',\n",
       " 'consuming',\n",
       " 'restful',\n",
       " 'apis',\n",
       " 'angular',\n",
       " 'jquery',\n",
       " 'javascript',\n",
       " 'css',\n",
       " 'microsoft',\n",
       " 'sql',\n",
       " 'server',\n",
       " 'and',\n",
       " 'postgresql',\n",
       " 'nunit',\n",
       " 'selenium',\n",
       " 'automated',\n",
       " 'testing',\n",
       " 'perforce',\n",
       " 'git',\n",
       " 'team',\n",
       " 'foundation',\n",
       " 'source',\n",
       " 'control',\n",
       " 'agile',\n",
       " 'scrum',\n",
       " 'development',\n",
       " 'methodology',\n",
       " 'ticket',\n",
       " 'management',\n",
       " 'go',\n",
       " 'live',\n",
       " 'support',\n",
       " 'during',\n",
       " 'phd',\n",
       " 'java',\n",
       " 'as',\n",
       " 'undergrad',\n",
       " 'assistant',\n",
       " 'manager',\n",
       " 'specialist',\n",
       " 'in',\n",
       " 'in-depth',\n",
       " 'inland',\n",
       " 'revenue',\n",
       " 'investigations',\n",
       " 'and',\n",
       " 'all',\n",
       " 'aspects',\n",
       " 'of',\n",
       " 'and',\n",
       " 'the',\n",
       " 'subsequent',\n",
       " 'completion',\n",
       " 'of',\n",
       " 'self-assessment',\n",
       " 'returns',\n",
       " 'general',\n",
       " 'windows',\n",
       " 'applications',\n",
       " 'psychologist',\n",
       " 'graduate',\n",
       " 'engineer',\n",
       " 'private',\n",
       " 'tutor',\n",
       " 'part',\n",
       " 'time',\n",
       " 'can',\n",
       " 'apply',\n",
       " 'mathematical',\n",
       " 'models',\n",
       " 'to',\n",
       " 'characterise',\n",
       " 'data',\n",
       " 'and',\n",
       " 'establish',\n",
       " 'trends',\n",
       " 'effective',\n",
       " 'and',\n",
       " 'confident',\n",
       " 'communicator',\n",
       " 'articulate',\n",
       " 'with',\n",
       " 'extensive',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'scientific',\n",
       " 'writing',\n",
       " 'proof-reading',\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalize_data(**kwargs):\n",
    "    tokenizer = kwargs['tokenizer']\n",
    "    normalizer = kwargs['token_format']\n",
    "    spelling = kwargs['spell_correct']\n",
    "    \n",
    "#     data = pd.DataFrame(['asc','asda','asdasdasd'], columns=['value_char'])\n",
    "    \n",
    "    # singularize tokens\n",
    "#     data = data[prefix].map(lambda l: map(lambda w: w.singularize(), l))\n",
    "\n",
    "    # Spell correct flag\n",
    "    # REALLY SHOULD NEVER BE USED\n",
    "#     if spelling:\n",
    "#         print(\"Spell Correction Invoked.....\")\n",
    "#         data[prefix] = data[prefix].map(lambda l: map(lambda wl: map(lambda w: w.correct(), wl), l))\n",
    "#         print(data[prefix].map(lambda l: map(lambda w: type(w), l)))\n",
    "\n",
    "    # filter out 'bad' words, normalize good ones\n",
    "    # w if w not in self.stopWords else wl.remove(w)\n",
    "    aa = cleanestes.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w in stopWords else w, wl), l))\n",
    "    aa = aa.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'s' else w, wl), l))\n",
    "    aa = aa.map(lambda l: map(lambda wl: map(lambda w: wl.remove(w) if w == '\\'d' else w, wl), l))\n",
    "\n",
    "    # remove tokens with length 1\n",
    "#     ree = re.compile(r'(\\'\\w)')\n",
    "#     rlen = len(data)\n",
    "#     tmp = data[prefix].copy()\n",
    "#     for index in range(0,rlen):\n",
    "#         wl_coll = list()\n",
    "#         for lst in tmp[index]:\n",
    "#             wl = list()\n",
    "#             for word in lst:\n",
    "#                 if not isinstance(word, types.NoneType):\n",
    "#                     if re.match(ree, word):\n",
    "#                         ree.sub('', word)\n",
    "#                     if len(word.strip().strip('.').strip(',')) > 1:\n",
    "#                         wl.append((word))\n",
    "#             wl_coll.append(WordList(wl))\n",
    "#         data[index] = wl_coll\n",
    "#     del tmp\n",
    "\n",
    "    # remove via regexp c'c pattern\n",
    "\n",
    "    # Stemming or lemmatization of tokens    \n",
    "    if normalizer == 'stem':\n",
    "        aa = aa.map(lambda l: map(lambda wl: map(lambda w: stemmer.stem(w) if w in wl and not isinstance(w, types.NoneType) else wl.remove(w), wl), l))\n",
    "#     elif normalizer == 'lemma':\n",
    "#         data[prefix] = data[prefix].map(lambda l: map(lambda wl: map(lambda w: w.lemmatize(), wl), l))\n",
    "#     elif normalizer == 'None':\n",
    "#         pass\n",
    "\n",
    "    aa = aa.map(lambda l: map(lambda wl: map(Word, wl), l))\n",
    "#     data[prefix] = data[prefix].map(lambda l: map(WordList, l))\n",
    "    \n",
    "    return aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize_data(**tokenizer_prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
